{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5061740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Optional, Callable, Any, Dict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd9617c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarse_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>concrete_compressive_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cement   blast_furnace_slag   fly_ash   water   superplasticizer  \\\n",
       "0      540.0                  0.0       0.0   162.0                2.5   \n",
       "1      540.0                  0.0       0.0   162.0                2.5   \n",
       "2      332.5                142.5       0.0   228.0                0.0   \n",
       "3      332.5                142.5       0.0   228.0                0.0   \n",
       "4      198.6                132.4       0.0   192.0                0.0   \n",
       "...      ...                  ...       ...     ...                ...   \n",
       "1025   276.4                116.0      90.3   179.6                8.9   \n",
       "1026   322.2                  0.0     115.6   196.0               10.4   \n",
       "1027   148.5                139.4     108.6   192.7                6.1   \n",
       "1028   159.1                186.7       0.0   175.6               11.3   \n",
       "1029   260.9                100.5      78.3   200.6                8.6   \n",
       "\n",
       "       coarse_aggregate   fine_aggregate   age   concrete_compressive_strength  \n",
       "0                1040.0            676.0    28                           79.99  \n",
       "1                1055.0            676.0    28                           61.89  \n",
       "2                 932.0            594.0   270                           40.27  \n",
       "3                 932.0            594.0   365                           41.05  \n",
       "4                 978.4            825.5   360                           44.30  \n",
       "...                 ...              ...   ...                             ...  \n",
       "1025              870.1            768.3    28                           44.28  \n",
       "1026              817.9            813.4    28                           31.18  \n",
       "1027              892.4            780.0    28                           23.70  \n",
       "1028              989.6            788.9    28                           32.77  \n",
       "1029              864.5            761.5    28                           32.40  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the concrete data\n",
    "df = pd.read_csv(\"data/concrete_data.csv\")\n",
    "\n",
    "# Display the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82141b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cement', ' blast_furnace_slag', ' fly_ash', ' water',\n",
       "       ' superplasticizer', ' coarse_aggregate', ' fine_aggregate', ' age',\n",
       "       ' concrete_compressive_strength'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate into train and test datasets\n",
    "\n",
    "train_df = df.sample(frac=0.7, random_state=42) # random state ensures we always get the same sample\n",
    "test_df = df.drop(train_df.index)\n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a7c9c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61.89, 44.3 , 42.33, 47.81, 41.84, 28.24, 52.12, 41.72, 53.69,\n",
       "       38.41, 50.46, 40.76, 33.12, 50.95,  9.87, 48.7 , 33.4 , 28.6 ,\n",
       "       24.4 , 35.3 , 49.2 , 55.6 , 54.1 , 56.1 , 68.3 , 66.9 , 60.29,\n",
       "       68.5 , 71.3 , 74.7 , 71.3 , 49.9 , 60.2 , 64.3 , 55.2 , 66.1 ,\n",
       "       72.99, 79.4 , 77.3 , 59.89, 62.5 , 57.6 , 67.8 , 24.89, 29.45,\n",
       "       10.38, 22.84, 33.96, 21.06, 26.4 , 35.34, 20.92, 24.9 , 28.47,\n",
       "       38.56, 10.76,  7.75, 30.39, 50.77, 53.9 , 22.32, 24.54, 31.35,\n",
       "       40.86, 30.23, 29.22, 38.33, 42.92, 44.4 , 45.08, 15.44, 26.77,\n",
       "       45.84, 29.65, 13.12, 36.64, 45.37, 48.67, 23.51, 39.15, 55.64,\n",
       "       52.04, 33.36, 44.14, 42.29, 42.22, 56.85, 21.91, 56.74, 33.73,\n",
       "       46.64, 50.08, 66.95, 52.2 , 46.23, 31.97, 43.06, 67.57, 41.37,\n",
       "       60.28, 56.83, 51.02, 44.13, 55.65, 47.28, 29.16, 67.87, 58.52,\n",
       "       53.58, 14.4 , 21.29, 15.82, 12.55,  8.49, 11.98, 19.42, 41.41,\n",
       "       27.22, 39.64, 51.26, 55.02, 49.99, 53.66, 56.06, 33.56, 57.03,\n",
       "       44.42, 53.39, 35.36, 25.02, 54.77, 22.75, 25.51, 36.84, 45.9 ,\n",
       "       61.46, 55.45, 33.49, 29.55, 37.92, 32.01, 72.1 , 39.  , 13.4 ,\n",
       "       59.49, 24.4 , 31.97, 27.74, 25.42, 27.94, 32.63, 25.75, 33.08,\n",
       "       24.07, 21.82, 21.07, 14.84, 32.05, 39.7 , 38.7 ,  7.51, 18.2 ,\n",
       "       37.44, 27.04, 18.42, 21.95, 24.1 , 25.08, 25.97, 27.63, 12.54,\n",
       "       27.53,  7.84, 30.57, 26.06, 43.7 , 30.14, 12.73, 20.87, 19.54,\n",
       "       47.71, 43.38, 29.89, 24.29, 29.23, 10.39, 27.87, 20.42, 13.57,\n",
       "       15.75, 24.28, 36.59, 14.14, 23.52,  6.81, 41.68,  9.56, 50.53,\n",
       "       17.17, 32.1 , 36.96, 43.57, 35.76, 38.7 , 14.31, 17.44, 37.91,\n",
       "       33.61, 40.86, 18.91, 30.96, 54.28, 14.5 , 26.06, 33.21, 44.09,\n",
       "       52.61,  6.27, 27.92, 39.  , 41.24, 14.99, 13.52, 24.  , 22.44,\n",
       "       21.16, 25.18, 21.65, 29.39, 41.05, 26.74, 61.92, 47.22, 51.04,\n",
       "       41.64, 19.69, 39.58, 48.79, 37.42, 34.68, 33.8 , 42.42, 55.94,\n",
       "       58.78, 20.77, 25.18, 16.5 , 15.42, 27.68, 26.86, 45.3 , 52.82,\n",
       "       42.64, 40.87, 33.3 , 38.46, 35.23, 32.76, 32.4 , 18.28, 31.42,\n",
       "       31.03, 25.56, 36.44, 32.96, 40.68, 19.01,  8.54, 32.24, 40.93,\n",
       "       23.79, 23.74, 35.86, 28.99,  9.74, 33.8 , 39.84, 27.23, 30.65,\n",
       "       15.34, 23.89, 22.93, 28.63, 28.94, 40.93, 17.96, 19.01,  8.54,\n",
       "       32.25, 23.52, 29.73, 52.45, 23.79, 46.23, 43.58, 35.87, 29.07,\n",
       "       33.42, 39.06, 15.57, 44.61, 52.83, 61.24, 33.31, 37.27, 41.54,\n",
       "       39.46, 37.92, 31.18])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy the target column from the input data into separate numpy arrays\n",
    "\n",
    "train_targets = train_df[' concrete_compressive_strength'].to_numpy()\n",
    "test_targets = test_df[' concrete_compressive_strength'].to_numpy()\n",
    "\n",
    "test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba74abaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 540. ,    0. ,    0. , ..., 1055. ,  676. ,   28. ],\n",
       "       [ 198.6,  132.4,    0. , ...,  978.4,  825.5,  360. ],\n",
       "       [ 190. ,  190. ,    0. , ...,  932. ,  670. ,   90. ],\n",
       "       ...,\n",
       "       [ 159.8,  250. ,    0. , ..., 1049.3,  688.2,   28. ],\n",
       "       [ 166. ,  259.7,    0. , ...,  858.8,  826.8,   28. ],\n",
       "       [ 322.2,    0. ,  115.6, ...,  817.9,  813.4,   28. ]],\n",
       "      shape=(309, 8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the target column from the input data to create input feature arrays\n",
    "\n",
    "train_features = train_df.drop(columns=[' concrete_compressive_strength']).to_numpy()\n",
    "test_features = test_df.drop(columns=[' concrete_compressive_strength']).to_numpy()\n",
    "\n",
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f99c0988",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_target_value = train_targets.max()\n",
    "train_targets = train_targets / max_target_value\n",
    "test_targets = test_targets / max_target_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "919ab793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "def mean_squared_error(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# MAE\n",
    "def mean_absolute_error(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "# RMSE\n",
    "def root_mean_squared_error(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# R2\n",
    "def r2_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21094448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.isVectorizable = False\n",
    "\n",
    "    def forward(self, input_data: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError(\"Forward method not implemented.\")\n",
    "\n",
    "    def randomize(self, weight_scale, bias_scale) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "364255a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationSigmoid(Layer):\n",
    "    def forward(self, input_data: np.ndarray) -> np.ndarray:\n",
    "        return 1 / (1 + np.exp(-input_data))\n",
    "\n",
    "class ActivationReLU(Layer):\n",
    "    def forward(self, input_data: np.ndarray) -> np.ndarray:\n",
    "        return np.maximum(0, input_data)\n",
    "\n",
    "class ActivationTanh(Layer):\n",
    "    def forward(self, input_data: np.ndarray) -> np.ndarray:\n",
    "        return np.tanh(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5f8cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a layer class for the MLP\n",
    "\n",
    "class Linear(Layer):\n",
    "    def __init__(self, size_input: int, size_hidden: int):\n",
    "        \"\"\"Initialize with weights and biases.\"\"\"\n",
    "        self.size_input = size_input\n",
    "        self.size_hidden = size_hidden\n",
    "        self.weights = self.init_weights()\n",
    "        self.bias = self.init_biases()\n",
    "        self.isVectorizable = True\n",
    "\n",
    "    def init_weights(self, weight_scale=0.1):\n",
    "        \"\"\"Initialize weights.\"\"\"\n",
    "        return np.random.randn(self.size_hidden, self.size_input) * weight_scale\n",
    "\n",
    "    def init_biases(self, bias_scale=0.001):\n",
    "        \"\"\"Initialize biases.\"\"\"\n",
    "        return np.full((self.size_hidden, 1), bias_scale)\n",
    "\n",
    "    def randomize(self, weight_scale=0.1, bias_scale=0.001):\n",
    "        \"\"\"Randomize weights and biases.\"\"\"\n",
    "        self.weights = self.init_weights(weight_scale=weight_scale)\n",
    "        self.bias = self.init_biases(bias_scale=bias_scale)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return np.dot(self.weights, X) + self.bias\n",
    "\n",
    "    def to_vector(self) -> np.ndarray:\n",
    "        \"\"\"Flatten weights and biases into a single vector.\"\"\"\n",
    "        return np.concatenate((self.weights.flatten(), self.bias.flatten()))\n",
    "\n",
    "    def from_vector(self, vector: np.ndarray) -> int:\n",
    "        \"\"\"Set weights and biases from a single vector.\"\"\"\n",
    "        self.weights = vector[:self.weights.size].reshape(self.weights.shape)\n",
    "        self.bias = vector[self.weights.size:].reshape(self.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8067fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bias:\n",
      "[[0.001]\n",
      " [0.001]\n",
      " [0.001]]\n",
      "weights:\n",
      "[[-0.12371272  0.08457245 -0.16923142  0.0058808  -0.18505051]\n",
      " [-0.06668216  0.13284941 -0.05112891 -0.11687925 -0.01673997]\n",
      " [-0.05532834 -0.03315371 -0.01871928 -0.10284434  0.02658368]]\n",
      "input:\n",
      "[[ 0.58578008]\n",
      " [ 1.51676275]\n",
      " [ 0.64277151]\n",
      " [-3.16637002]\n",
      " [-0.3927995 ]]\n",
      "output:\n",
      "[[0.00209772]\n",
      " [0.50723414]\n",
      " [0.22147241]]\n",
      "\n",
      "vector:\n",
      "[-0.12371272  0.08457245 -0.16923142  0.0058808  -0.18505051 -0.06668216\n",
      "  0.13284941 -0.05112891 -0.11687925 -0.01673997 -0.05532834 -0.03315371\n",
      " -0.01871928 -0.10284434  0.02658368  0.001       0.001       0.001     ]\n",
      "layer2 bias:\n",
      "[[0.001]\n",
      " [0.001]\n",
      " [0.001]]\n",
      "layer2 weights:\n",
      "[[-0.12371272  0.08457245 -0.16923142  0.0058808  -0.18505051]\n",
      " [-0.06668216  0.13284941 -0.05112891 -0.11687925 -0.01673997]\n",
      " [-0.05532834 -0.03315371 -0.01871928 -0.10284434  0.02658368]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the Linear class\n",
    "layer = Linear(size_input=5, size_hidden=3)\n",
    "X_sample = np.random.randn(1, 5).T\n",
    "output = layer.forward(X_sample)\n",
    "\n",
    "vector = layer.to_vector()\n",
    "layer2 = Linear(size_input=5, size_hidden=3)\n",
    "layer2.from_vector(vector)\n",
    "\n",
    "print(f\"\"\"\n",
    "bias:\n",
    "{layer.bias}\n",
    "weights:\n",
    "{layer.weights}\n",
    "input:\n",
    "{X_sample}\n",
    "output:\n",
    "{output}\n",
    "\n",
    "vector:\n",
    "{vector}\n",
    "layer2 bias:\n",
    "{layer2.bias}\n",
    "layer2 weights:\n",
    "{layer2.weights}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec4dc76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential:\n",
    "    def __init__(self, *layers: Layer, randomize: bool = True):\n",
    "        self.layers = layers\n",
    "        self.vectorizable_layers: List[Linear] = [layer for layer in self.layers if layer.isVectorizable]\n",
    "        self.vector_indexes = []\n",
    "        index = 0\n",
    "        for layer in self.vectorizable_layers:\n",
    "            size_layer_params = layer.weights.size + layer.bias.size\n",
    "            self.vector_indexes.append((index, index + size_layer_params))\n",
    "            index += size_layer_params\n",
    "\n",
    "        if randomize:\n",
    "            self.randomize()\n",
    "\n",
    "    def randomize(self, weight_scale=0.1, bias_scale=0.001):\n",
    "        for layer in self.layers:\n",
    "            layer.randomize(weight_scale=weight_scale, bias_scale=bias_scale)\n",
    "\n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        output = X\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "\n",
    "    def to_vector(self) -> np.ndarray:\n",
    "        \"\"\"Concatenate parameters from all layers into a single vector.\"\"\"\n",
    "        param_vector = np.array([])\n",
    "        for layer in self.vectorizable_layers:\n",
    "            param_vector = np.concatenate((param_vector, layer.to_vector()))\n",
    "        return param_vector\n",
    "\n",
    "    def from_vector(self, param_vector: np.ndarray):\n",
    "        \"\"\"Set parameters from all layers from a single vector.\"\"\"\n",
    "        for i in range(len(self.vectorizable_layers)):\n",
    "            start_idx, end_idx = self.vector_indexes[i]\n",
    "            self.vectorizable_layers[i].from_vector(param_vector[start_idx:end_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a6628e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input:\n",
      "[[ 0.44390077]\n",
      " [ 0.00694555]\n",
      " [-1.03990713]\n",
      " [-1.65346617]\n",
      " [-2.15941018]]\n",
      "output:\n",
      "[[-0.06047346]]\n",
      "\n",
      "vector:\n",
      "[ 0.02460011  0.11573055  0.08787026  0.10130325 -0.02665505  0.0264727\n",
      " -0.12350594 -0.03511868 -0.08078707 -0.04476722  0.01436895 -0.02303657\n",
      " -0.13193137  0.02265369 -0.03431822  0.001       0.001       0.001\n",
      " -0.03537712  0.10110405  0.06288978  0.03164456 -0.04511364 -0.03702526\n",
      "  0.00948802  0.00247516 -0.10865817  0.06168646  0.04342818  0.10446368\n",
      "  0.001       0.001       0.001       0.001       0.0966726  -0.04528162\n",
      " -0.06505013 -0.11047835  0.001     ]\n",
      "\n",
      "\n",
      "initial model2 output:\n",
      "[[-0.13141654]]\n",
      "\n",
      "model2 output after from_vector:\n",
      "[[-0.06047346]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the Sequential class\n",
    "\n",
    "mlp = Sequential(\n",
    "    Linear(size_input=5, size_hidden=3),\n",
    "    ActivationReLU(),\n",
    "    Linear(size_input=3, size_hidden=4),\n",
    "    ActivationSigmoid(),\n",
    "    Linear(size_input=4, size_hidden=1)\n",
    ")\n",
    "X_sample = np.random.randn(1, 5).T\n",
    "output = mlp.forward(X_sample)\n",
    "vector = mlp.to_vector()\n",
    "print(f\"\"\"\n",
    "input:\n",
    "{X_sample}\n",
    "output:\n",
    "{output}\n",
    "\n",
    "vector:\n",
    "{vector}\n",
    "\"\"\")\n",
    "\n",
    "mlp.randomize()\n",
    "print(f\"\"\"\n",
    "initial model2 output:\n",
    "{mlp.forward(X_sample)}\n",
    "\"\"\")\n",
    "\n",
    "mlp.from_vector(vector)\n",
    "print(f\"\"\"model2 output after from_vector:\n",
    "{mlp.forward(X_sample)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc7987b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of AI class for training the MLP with our PSO\n",
    "\n",
    "@dataclass\n",
    "class AccelerationCoefficients:\n",
    "    inertia_weight: float\n",
    "    cognitive_weight: float\n",
    "    social_weight: float\n",
    "    global_best_weight: float\n",
    "    jump_size: float\n",
    "    max_velocity: float\n",
    "    max_position: float\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, position: np.ndarray, accel_coeff: AccelerationCoefficients, fitness: float):\n",
    "        self.accel_coeff = accel_coeff\n",
    "        # Initialize other attributes like position, velocity, personal best, etc.\n",
    "        self.position = position\n",
    "        self.velocity = np.random.randn(position.shape[0]) * 0.1\n",
    "        self.fittest = fitness\n",
    "        self.informants: List[Particle] = []\n",
    "\n",
    "        self.best_personal: np.ndarray = position.copy()\n",
    "\n",
    "    def get_best_informant(self):\n",
    "        informant_fittest = None\n",
    "        best_informant = None\n",
    "        for informant in self.informants:\n",
    "            if best_informant is None or informant.fittest < informant_fittest:\n",
    "                informant_fittest = informant.fittest\n",
    "                best_informant = informant\n",
    "        return best_informant.position\n",
    "\n",
    "    def update_velocity(self, best_global):\n",
    "        best_informant = self.get_best_informant()\n",
    "        for i in range(len(self.position)):\n",
    "            b = np.random.random() * self.accel_coeff.cognitive_weight\n",
    "            c = np.random.random() * self.accel_coeff.social_weight\n",
    "            d = np.random.random() * self.accel_coeff.global_best_weight\n",
    "            inertia = self.accel_coeff.inertia_weight * self.velocity[i]\n",
    "            velocity_cognitive = b * (self.best_personal[i] - self.position[i])\n",
    "            velocity_social = c * (best_informant[i] - self.position[i])\n",
    "            velocity_global = d * (best_global[i] - self.position[i])\n",
    "            new_velocity = inertia + velocity_cognitive + velocity_social + velocity_global\n",
    "            self.velocity[i] = np.clip(new_velocity, -self.accel_coeff.max_velocity, self.accel_coeff.max_velocity)\n",
    "\n",
    "    def update_position(self):\n",
    "        self.position += self.velocity * self.accel_coeff.jump_size\n",
    "        self.position = np.clip(self.position, -self.accel_coeff.max_position, self.accel_coeff.max_position)\n",
    "\n",
    "class ParticleSwarmOptimisation:\n",
    "    def __init__(\n",
    "            self,\n",
    "            X: np.ndarray[tuple[int, int]],\n",
    "            Y: np.ndarray[tuple[int]],\n",
    "            swarm_size: int,\n",
    "            accel_coeff: AccelerationCoefficients,\n",
    "            num_informants: int,\n",
    "            loss_function,\n",
    "            particle_initial_position_scale: Tuple[float, float],\n",
    "            model: Sequential,\n",
    "        ):\n",
    "        self.accel_coeff = accel_coeff\n",
    "        self.swarm_size = swarm_size\n",
    "        self.num_informants = num_informants\n",
    "\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "        self.loss_function = loss_function\n",
    "        self.model = model\n",
    "\n",
    "        self.losses = []\n",
    "        self.avg_fitnesses = []\n",
    "\n",
    "        self.population: List[Particle] = []\n",
    "        for _ in range(swarm_size):\n",
    "            self.model.randomize(weight_scale=particle_initial_position_scale[0], bias_scale=particle_initial_position_scale[1])\n",
    "            particle_fitness = self.loss_function(self.Y, self.model.forward(self.X))\n",
    "            self.population.append(Particle(position=self.model.to_vector(), accel_coeff=accel_coeff, fitness=particle_fitness))\n",
    "\n",
    "        self.best_global: np.ndarray = self.population[0].position.copy()\n",
    "        self.best_global_fitness: float = self.population[0].fittest\n",
    "\n",
    "    def update_informants(self):\n",
    "        if self.num_informants >= self.swarm_size:\n",
    "            raise ValueError(\"Number of informants must be less than swarm size.\")\n",
    "        for particle in self.population:\n",
    "            others = [p for p in self.population if p is not particle]\n",
    "            particle.informants = np.random.choice(others, size=self.num_informants, replace=False)\n",
    "\n",
    "    def update_best_global(self):\n",
    "        loss = 0.0\n",
    "        fitnesses = []\n",
    "        for particle in self.population:\n",
    "            self.model.from_vector(particle.position)\n",
    "            fitness = self.loss_function(self.Y, self.model.forward(self.X))\n",
    "            fitnesses.append(fitness)\n",
    "            loss += fitness\n",
    "            if fitness < particle.fittest:\n",
    "                particle.best_personal = particle.position.copy()\n",
    "                particle.fittest = fitness\n",
    "                if self.best_global_fitness is None or fitness < self.best_global_fitness:\n",
    "                    self.best_global = particle.position.copy()\n",
    "                    self.best_global_fitness = fitness\n",
    "        return np.mean(fitnesses)\n",
    "\n",
    "    def get_accuracy(self, x, y_true) -> float:\n",
    "        \"\"\"Evaluate the accuracy in percent of the best global model on given data.\"\"\"\n",
    "        self.model.from_vector(self.best_global)\n",
    "        y_pred = self.model.forward(x)\n",
    "\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        accuracy = 100 * (1.0 - mae / np.mean(np.abs(y_true)))\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    def update_velocities(self):\n",
    "        for particle in self.population:\n",
    "            particle.update_velocity(self.best_global)\n",
    "\n",
    "    def update_positions(self):\n",
    "        for particle in self.population:\n",
    "            particle.update_position()\n",
    "\n",
    "    def plot(self, epoch, avg_fitness):\n",
    "        if epoch % 10 == 0:\n",
    "            self.avg_fitnesses.append(avg_fitness)\n",
    "            self.losses.append(self.best_global_fitness)\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(self.losses, label=\"Loss\")\n",
    "            ax.plot(\n",
    "                self.avg_fitnesses,\n",
    "                label=\"Average Fitness\",\n",
    "                linestyle=\"--\"\n",
    "            )\n",
    "            ax.set_xlabel(\"Step\")\n",
    "            ax.set_ylabel(\"Loss\")\n",
    "            ax.set_title(\"Training Loss\")\n",
    "            ax.legend()\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "            \n",
    "    def train_epoch(self):\n",
    "        avg_fitness = self.update_best_global()\n",
    "        self.update_velocities()\n",
    "        self.update_positions()\n",
    "        return avg_fitness\n",
    "\n",
    "    def train(self, epochs):\n",
    "        self.update_informants()\n",
    "        for epoch in range(epochs):\n",
    "            avg_fitness = self.train_epoch()\n",
    "            self.plot(epoch, avg_fitness)\n",
    "        return (self.best_global, self.best_global_fitness, self.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0a41068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of AI class for training the MLP with our PSO\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AccelerationCoefficients:\n",
    "    inertia_weight: float\n",
    "    cognitive_weight: float\n",
    "    social_weight: float\n",
    "    global_best_weight: float\n",
    "    jump_size: float\n",
    "    max_velocity: float\n",
    "    max_position: float\n",
    "\n",
    "\n",
    "class Particle:\n",
    "    def __init__(\n",
    "        self,\n",
    "        position: np.ndarray,\n",
    "        accel_coeff: AccelerationCoefficients,\n",
    "        fitness: float,\n",
    "    ):\n",
    "        self.accel_coeff = accel_coeff\n",
    "        # Initialize other attributes like position, velocity, personal best, etc.\n",
    "        self.position = position\n",
    "        self.velocity = np.random.randn(position.shape[0]) * 0.1\n",
    "        self.fittest = fitness\n",
    "        self.informants: List[Particle] = []\n",
    "\n",
    "        self.best_personal: np.ndarray = position.copy()\n",
    "\n",
    "    def get_best_informant(self):\n",
    "        informant_fittest = None\n",
    "        best_informant = None\n",
    "        for informant in self.informants:\n",
    "            if best_informant is None or informant.fittest < informant_fittest:\n",
    "                informant_fittest = informant.fittest\n",
    "                best_informant = informant\n",
    "        return best_informant.position\n",
    "\n",
    "    def update_velocity(self, best_global):\n",
    "        best_informant = self.get_best_informant()\n",
    "        for i in range(len(self.position)):\n",
    "            b = np.random.random() * self.accel_coeff.cognitive_weight\n",
    "            c = np.random.random() * self.accel_coeff.social_weight\n",
    "            d = np.random.random() * self.accel_coeff.global_best_weight\n",
    "            inertia = self.accel_coeff.inertia_weight * self.velocity[i]\n",
    "            velocity_cognitive = b * (self.best_personal[i] - self.position[i])\n",
    "            velocity_social = c * (best_informant[i] - self.position[i])\n",
    "            velocity_global = d * (best_global[i] - self.position[i])\n",
    "            new_velocity = (\n",
    "                inertia + velocity_cognitive + velocity_social + velocity_global\n",
    "            )\n",
    "            self.velocity[i] = np.clip(\n",
    "                new_velocity,\n",
    "                -self.accel_coeff.max_velocity,\n",
    "                self.accel_coeff.max_velocity,\n",
    "            )\n",
    "\n",
    "    def update_position(self):\n",
    "        self.position += self.velocity * self.accel_coeff.jump_size\n",
    "        self.position = np.clip(\n",
    "            self.position, -self.accel_coeff.max_position, self.accel_coeff.max_position\n",
    "        )\n",
    "\n",
    "\n",
    "class ParticleSwarmOptimisation:\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: np.ndarray[tuple[int, int]],\n",
    "        Y: np.ndarray[tuple[int]],\n",
    "        swarm_size: int,\n",
    "        accel_coeff: AccelerationCoefficients,\n",
    "        num_informants: int,\n",
    "        loss_function,\n",
    "        particle_initial_position_scale: Tuple[float, float],\n",
    "        model: Sequential,\n",
    "    ):\n",
    "        self.accel_coeff = accel_coeff\n",
    "        self.swarm_size = swarm_size\n",
    "        self.num_informants = num_informants\n",
    "\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "        self.loss_function = loss_function\n",
    "        self.model = model\n",
    "\n",
    "        self.losses = []\n",
    "        self.avg_fitnesses = []\n",
    "\n",
    "        self.population: List[Particle] = []\n",
    "        for _ in range(swarm_size):\n",
    "            self.model.randomize(\n",
    "                weight_scale=particle_initial_position_scale[0],\n",
    "                bias_scale=particle_initial_position_scale[1],\n",
    "            )\n",
    "            particle_fitness = self.loss_function(self.Y, self.model.forward(self.X))\n",
    "            self.population.append(\n",
    "                Particle(\n",
    "                    position=self.model.to_vector(),\n",
    "                    accel_coeff=accel_coeff,\n",
    "                    fitness=particle_fitness,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.best_global: np.ndarray = self.population[0].position.copy()\n",
    "        self.best_global_fitness: float = self.population[0].fittest\n",
    "\n",
    "    def update_informants_random(self):\n",
    "        if self.num_informants >= self.swarm_size:\n",
    "            raise ValueError(\"Number of informants must be less than swarm size.\")\n",
    "        for particle in self.population:\n",
    "            others = [p for p in self.population if p is not particle]\n",
    "            particle.informants = np.random.choice(\n",
    "                others, size=self.num_informants, replace=False\n",
    "            )\n",
    "\n",
    "    def update_informants_nearest(self):\n",
    "        if self.num_informants >= self.swarm_size:\n",
    "            raise ValueError(\"Number of informants must be less than swarm size.\")\n",
    "        for particle in self.population:\n",
    "            distances = []\n",
    "            for other in self.population:\n",
    "                if other is not particle:\n",
    "                    dist = np.linalg.norm(particle.position - other.position)\n",
    "                    distances.append((dist, other))\n",
    "            distances.sort(key=lambda x: x[0])\n",
    "            particle.informants = [distances[i][1] for i in range(self.num_informants)]\n",
    "\n",
    "    def update_best_global(self):\n",
    "        loss = 0.0\n",
    "        fitnesses = []\n",
    "        for particle in self.population:\n",
    "            self.model.from_vector(particle.position)\n",
    "            fitness = self.loss_function(self.Y, self.model.forward(self.X))\n",
    "            fitnesses.append(fitness)\n",
    "            loss += fitness\n",
    "            if fitness < particle.fittest:\n",
    "                particle.best_personal = particle.position.copy()\n",
    "                particle.fittest = fitness\n",
    "                if (\n",
    "                    self.best_global_fitness is None\n",
    "                    or fitness < self.best_global_fitness\n",
    "                ):\n",
    "                    self.best_global = particle.position.copy()\n",
    "                    self.best_global_fitness = fitness\n",
    "        return np.mean(fitnesses)\n",
    "\n",
    "    def get_accuracy(self, x, y_true) -> float:\n",
    "        \"\"\"Evaluate the accuracy in percent of the best global model on given data.\"\"\"\n",
    "        self.model.from_vector(self.best_global)\n",
    "        y_pred = self.model.forward(x)\n",
    "\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        accuracy = 100 * (1.0 - mae / np.mean(np.abs(y_true)))\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    def update_velocities(self):\n",
    "        for particle in self.population:\n",
    "            particle.update_velocity(self.best_global)\n",
    "\n",
    "    def update_positions(self):\n",
    "        for particle in self.population:\n",
    "            particle.update_position()\n",
    "\n",
    "    def plot(self, epoch, avg_fitness):\n",
    "        if epoch % 1 == 0:\n",
    "            self.avg_fitnesses.append(avg_fitness)\n",
    "            self.losses.append(self.best_global_fitness)\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(self.losses, label=\"Loss\")\n",
    "            ax.plot(self.avg_fitnesses, label=\"Average Fitness\", linestyle=\"--\")\n",
    "            ax.set_xlabel(\"Step\")\n",
    "            ax.set_ylabel(\"Loss\")\n",
    "            ax.set_title(\"Training Loss\")\n",
    "            ax.legend()\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "    def train_epoch(self):\n",
    "        avg_fitness = self.update_best_global()\n",
    "        self.update_velocities()\n",
    "        self.update_positions()\n",
    "        return avg_fitness\n",
    "\n",
    "    def train(self, epochs):\n",
    "        # self.update_informants_random()\n",
    "        for epoch in range(epochs):\n",
    "            self.update_informants_nearest()\n",
    "            avg_fitness = self.train_epoch()\n",
    "            self.plot(epoch, avg_fitness)\n",
    "        return (self.best_global, self.best_global_fitness, self.losses)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff34235",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m all_final_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m     mlp \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m(\n\u001b[1;32m     19\u001b[0m         Linear(size_input\u001b[38;5;241m=\u001b[39mtrain_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], size_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m),\n\u001b[1;32m     20\u001b[0m         ActivationReLU(),\n\u001b[1;32m     21\u001b[0m         Linear(size_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, size_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m     22\u001b[0m         ActivationReLU(),\n\u001b[1;32m     23\u001b[0m         Linear(size_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, size_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# predictions = mlp.forward(test_features.T)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# plt.scatter(test_targets, predictions)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# plt.plot([test_targets.min(), test_targets.max()], [test_targets.min(), test_targets.max()], 'k--', lw=2)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     swarm_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m45\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Timestamp for the entire experiment\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Main output directory\n",
    "main_dir = f\"./results/{timestamp}\"\n",
    "os.makedirs(main_dir, exist_ok=True)\n",
    "\n",
    "all_final_train_accuracies = []\n",
    "all_final_test_accuracies = []\n",
    "all_final_losses = []\n",
    "\n",
    "\n",
    "for run_id in range(1, 11):\n",
    "\n",
    "    mlp = Sequential(\n",
    "        Linear(size_input=train_features.shape[1], size_hidden=8),\n",
    "        ActivationReLU(),\n",
    "        Linear(size_input=8, size_hidden=4),\n",
    "        ActivationReLU(),\n",
    "        Linear(size_input=4, size_hidden=1),\n",
    "    )\n",
    "\n",
    "    # predictions = mlp.forward(test_features.T)\n",
    "\n",
    "    # plt.scatter(test_targets, predictions)\n",
    "    # plt.xlabel(\"True Values\")\n",
    "    # plt.ylabel(\"Predictions\")\n",
    "    # plt.title(\"Predictions vs True Values\")\n",
    "    # plt.plot([test_targets.min(), test_targets.max()], [test_targets.min(), test_targets.max()], 'k--', lw=2)\n",
    "    # plt.show()\n",
    "\n",
    "    swarm_size = 45\n",
    "    epochs = 10\n",
    "    accel_coeff = AccelerationCoefficients(\n",
    "        inertia_weight=0.708,\n",
    "        cognitive_weight=1.898,\n",
    "        social_weight=0.351,\n",
    "        global_best_weight=0.684,\n",
    "        jump_size=0.851,\n",
    "        max_velocity=0.9,\n",
    "        max_position=3.87,\n",
    "    )\n",
    "    num_informants = 4\n",
    "    particle_initial_position_scale = (0.0001, 0.05)\n",
    "    loss_function = mean_squared_error\n",
    "\n",
    "    pso = ParticleSwarmOptimisation(\n",
    "        X=train_features.T,\n",
    "        Y=train_targets,\n",
    "        swarm_size=swarm_size,\n",
    "        accel_coeff=accel_coeff,\n",
    "        num_informants=num_informants,\n",
    "        loss_function=loss_function,\n",
    "        particle_initial_position_scale=particle_initial_position_scale,\n",
    "        model=mlp,\n",
    "    )\n",
    "\n",
    "    (final_position, final_score, losses) = pso.train(epochs)\n",
    "    # print(f\"Final particle fitness: {final_score}\")\n",
    "    # print(f\"Final particle position sample: {final_position[:5]}\")\n",
    "    mlp.from_vector(final_position)\n",
    "    # predictions = mlp.forward(test_features.T)\n",
    "\n",
    "    # plt.scatter(test_targets, predictions)\n",
    "    # plt.xlabel(\"True Values\")\n",
    "    # plt.ylabel(\"Predictions\")\n",
    "    # plt.title(\"Predictions vs True Values\")\n",
    "    # plt.plot(\n",
    "    #     [test_targets.min(), test_targets.max()],\n",
    "    #     [test_targets.min(), test_targets.max()],\n",
    "    #     \"k--\",\n",
    "    #     lw=2,\n",
    "    # )\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.plot(losses)\n",
    "    # plt.yscale(\"log\")\n",
    "    # plt.xlabel(\"Epoch\")\n",
    "    # plt.ylabel(\"Loss\")\n",
    "    # plt.title(\"Training Loss over Epochs\")\n",
    "    # plt.show()\n",
    "\n",
    "    # Accuracy\n",
    "    test_accuracy = pso.get_accuracy(test_features.T, test_targets)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    all_final_test_accuracies.append(test_accuracy)\n",
    "\n",
    "    train_accuracy = pso.get_accuracy(train_features.T, train_targets)\n",
    "    print(f\"Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    all_final_train_accuracies.append(train_accuracy)\n",
    "\n",
    "    all_final_losses.append(final_score)\n",
    "\n",
    "    # print(f\"\"\"\n",
    "    # Params:\n",
    "    # model: MLP with layers {[type(layer).__name__ for layer in mlp.layers]}\n",
    "    # swarm_size: {swarm_size}\n",
    "    # epochs: {epochs}\n",
    "    # accel_coeff: {accel_coeff}\n",
    "    # num_informants: {num_informants}\n",
    "    # loss_function: {loss_function.__name__}\n",
    "    # \"\"\")\n",
    "\n",
    "avg_loss = np.mean(all_final_losses)\n",
    "avg_train_acc = np.mean(all_final_train_accuracies)\n",
    "avg_test_acc = np.mean(all_final_test_accuracies)\n",
    "\n",
    "std_train_acc = np.std(all_final_train_accuracies)\n",
    "std_test_acc = np.std(all_final_test_accuracies)\n",
    "\n",
    "print(\"\\n===== Summary over 10 runs =====\")\n",
    "print(f\"Average loss: {avg_loss:.4f}\")\n",
    "print(f\"Average train accuracy: {avg_train_acc:.2f}%\")\n",
    "print(f\"Average test accuracy:  {avg_test_acc:.2f}%\")\n",
    "print(f\"Train accuracy std: {std_train_acc:.2f}\")\n",
    "print(f\"Test accuracy std:  {std_test_acc:.2f}\")\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(all_final_losses, marker=\"o\")\n",
    "# plt.title(\"Final Loss per Run\")\n",
    "# plt.xlabel(\"Run\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_final_train_accuracies, marker=\"o\")\n",
    "plt.title(\"Train Accuracy per Run\")\n",
    "plt.xlabel(\"Run\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.savefig(f\"{main_dir}/final train accuracies.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_final_test_accuracies, marker=\"o\")\n",
    "plt.title(\"Test Accuracy per Run\")\n",
    "plt.xlabel(\"Run\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.savefig(f\"{main_dir}/final test accuracies.png\")\n",
    "plt.show()\n",
    "\n",
    "summary_path = f\"{main_dir}/experiment_summary.txt\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "\n",
    "    f.write(\"===== GLOBAL EXPERIMENT SUMMARY =====\\n\\n\")\n",
    "\n",
    "    f.write(\"=== ANN Structure ===\\n\")\n",
    "    f.write(\"Topology: 8-4-1 with ReLU activations\\n\\n\")\n",
    "\n",
    "    f.write(\"=== PSO Hyperparameters ===\\n\")\n",
    "    f.write(f\"Swarm size: {swarm_size}\\n\")\n",
    "    f.write(f\"Epochs: {epochs}\\n\")\n",
    "    f.write(f\"Inertia: {accel_coeff.inertia_weight}\\n\")\n",
    "    f.write(f\"Cognitive: {accel_coeff.cognitive_weight}\\n\")\n",
    "    f.write(f\"Social: {accel_coeff.social_weight}\\n\")\n",
    "    f.write(f\"Global best weight: {accel_coeff.global_best_weight}\\n\")\n",
    "    f.write(f\"Jump size: {accel_coeff.jump_size}\\n\")\n",
    "    f.write(f\"Max velocity: {accel_coeff.max_velocity}\\n\")\n",
    "    f.write(f\"Max position: {accel_coeff.max_position}\\n\")\n",
    "    f.write(f\"Informants: {num_informants}\\n\")\n",
    "    f.write(f\"Initial position scale: {particle_initial_position_scale}\\n\\n\")\n",
    "\n",
    "    f.write(\"=== RESULTS OVER 10 RUNS ===\\n\")\n",
    "    for i in range(10):\n",
    "        f.write(f\"Run {i+1}: Loss = {all_final_losses[i]:.5f}, \"\n",
    "                f\"Train Acc = {all_final_train_accuracies[i]:.2f}%, \"\n",
    "                f\"Test Acc = {all_final_test_accuracies[i]:.2f}%\\n\")\n",
    "\n",
    "    f.write(\"\\n=== Averages ===\\n\")\n",
    "    f.write(f\"Average Loss: {np.mean(all_final_losses):.6f}\\n\")\n",
    "    f.write(f\"Average Train Accuracy: {np.mean(all_final_train_accuracies):.2f}%\\n\")\n",
    "    f.write(f\"Average Test Accuracy: {np.mean(all_final_test_accuracies):.2f}%\\n\\n\")\n",
    "\n",
    "    f.write(\"=== Standard Deviations ===\\n\")\n",
    "    f.write(f\"Std Train Acc: {np.std(all_final_train_accuracies):.2f}\\n\")\n",
    "    f.write(f\"Std Test Acc: {np.std(all_final_test_accuracies):.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1128db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAATYFJREFUeJzt3Xl8U1X+//FXmrZpC20pS8tWKKLIvi+yKPq1ioooiIqow6IyoyIuHWcElUVcEGZ0cERF+KGIIwOOCiqbYkdcUXZGdhELFbqA0Ja20CXJ74/bpg1toZS0N03ez8cjj9zce+7NJy2ad88991yL0+l0IiIiIuIjAswuQERERMSTFG5ERETEpyjciIiIiE9RuBERERGfonAjIiIiPkXhRkRERHyKwo2IiIj4FIUbERER8SkKNyIiIuJTFG5EpNqNGTOGuLi4Ku07bdo0LBaLZwsSEZ+mcCPixywWS6Ue69atM7tUU4wZM4a6deuaXYaInCeL7i0l4r/+9a9/ub1etGgRa9eu5d1333Vbf8011xATE1Pl9ykoKMDhcGCz2c5738LCQgoLCwkJCany+1fVmDFj+OCDD8jOzq7x9xaRqgs0uwARMc/dd9/t9vqHH35g7dq1ZdafKTc3l7CwsEq/T1BQUJXqAwgMDCQwUP+rEpHK02kpETmrK6+8ko4dO7J582auuOIKwsLCePLJJwH4+OOPGTx4ME2bNsVms9G6dWueffZZ7Ha72zHOHHOTlJSExWLh73//O/PmzaN169bYbDZ69erFxo0b3fYtb8yNxWLhoYceYvny5XTs2BGbzUaHDh1Ys2ZNmfrXrVtHz549CQkJoXXr1rz55pseH8fzn//8hx49ehAaGkrDhg25++67OXz4sFub1NRUxo4dS/PmzbHZbDRp0oSbb76ZpKQkV5tNmzYxaNAgGjZsSGhoKK1ateKee+7xWJ0i/kJ/DonIOf3+++9cf/313HHHHdx9992uU1QLFy6kbt26JCQkULduXf773/8yZcoUsrKy+Nvf/nbO4y5evJiTJ0/ypz/9CYvFwqxZs7jllls4cODAOXt7vv32Wz766CMefPBBwsPD+ec//8nw4cM5dOgQDRo0AGDr1q1cd911NGnShGeeeQa73c706dNp1KjRhf9QiixcuJCxY8fSq1cvZsyYQVpaGq+88grfffcdW7dupV69egAMHz6cnTt3MmHCBOLi4khPT2ft2rUcOnTI9fraa6+lUaNGTJw4kXr16pGUlMRHH33ksVpF/IZTRKTI+PHjnWf+b2HgwIFOwDl37twy7XNzc8us+9Of/uQMCwtznj592rVu9OjRzpYtW7pe//rrr07A2aBBA+fx48dd6z/++GMn4Pz0009d66ZOnVqmJsAZHBzs3L9/v2vd9u3bnYDz1Vdfda0bMmSIMywszHn48GHXup9//tkZGBhY5pjlGT16tLNOnToVbs/Pz3dGR0c7O3bs6Dx16pRr/YoVK5yAc8qUKU6n0+k8ceKEE3D+7W9/q/BYy5YtcwLOjRs3nrMuETk7nZYSkXOy2WyMHTu2zPrQ0FDX8smTJzl27BiXX345ubm57Nmz55zHHTFiBFFRUa7Xl19+OQAHDhw4577x8fG0bt3a9bpz585ERES49rXb7XzxxRcMHTqUpk2butpdfPHFXH/99ec8fmVs2rSJ9PR0HnzwQbcBz4MHD6Zt27asXLkSMH5OwcHBrFu3jhMnTpR7rOIenhUrVlBQUOCR+kT8lcKNiJxTs2bNCA4OLrN+586dDBs2jMjISCIiImjUqJFrMHJmZuY5j9uiRQu318VBp6IAcLZ9i/cv3jc9PZ1Tp05x8cUXl2lX3rqqOHjwIACXXnppmW1t27Z1bbfZbMycOZPVq1cTExPDFVdcwaxZs0hNTXW1HzhwIMOHD+eZZ56hYcOG3Hzzzbz99tvk5eV5pFYRf6JwIyLnVLqHplhGRgYDBw5k+/btTJ8+nU8//ZS1a9cyc+ZMABwOxzmPa7Vay13vrMQMFReyrxkeffRR9u3bx4wZMwgJCWHy5Mm0a9eOrVu3AsYg6Q8++ID169fz0EMPcfjwYe655x569OihS9FFzpPCjYhUybp16/j9999ZuHAhjzzyCDfeeCPx8fFup5nMFB0dTUhICPv37y+zrbx1VdGyZUsA9u7dW2bb3r17XduLtW7dmj//+c98/vnn7Nixg/z8fF566SW3NpdddhnPP/88mzZt4r333mPnzp0sWbLEI/WK+AuFGxGpkuKek9I9Jfn5+bz++utmleTGarUSHx/P8uXLOXLkiGv9/v37Wb16tUfeo2fPnkRHRzN37ly300erV69m9+7dDB48GDDmBTp9+rTbvq1btyY8PNy134kTJ8r0OnXt2hVAp6ZEzpMuBReRKunXrx9RUVGMHj2ahx9+GIvFwrvvvutVp4WmTZvG559/Tv/+/XnggQew2+3MmTOHjh07sm3btkodo6CggOeee67M+vr16/Pggw8yc+ZMxo4dy8CBAxk5cqTrUvC4uDgee+wxAPbt28fVV1/N7bffTvv27QkMDGTZsmWkpaVxxx13APDOO+/w+uuvM2zYMFq3bs3JkyeZP38+ERER3HDDDR77mYj4A4UbEamSBg0asGLFCv785z/z9NNPExUVxd13383VV1/NoEGDzC4PgB49erB69Woef/xxJk+eTGxsLNOnT2f37t2VupoLjN6oyZMnl1nfunVrHnzwQcaMGUNYWBgvvvgiTzzxBHXq1GHYsGHMnDnTdQVUbGwsI0eOJDExkXfffZfAwEDatm3L+++/z/DhwwFjQPGGDRtYsmQJaWlpREZG0rt3b9577z1atWrlsZ+JiD/QvaVExO8MHTqUnTt38vPPP5tdiohUA425ERGfdurUKbfXP//8M6tWreLKK680pyARqXbquRERn9akSRPGjBnDRRddxMGDB3njjTfIy8tj69atXHLJJWaXJyLVQGNuRMSnXXfddfz73/8mNTUVm81G3759eeGFFxRsRHyYem5ERETEp2jMjYiIiPgUhRsRERHxKX435sbhcHDkyBHCw8OxWCxmlyMiIiKV4HQ6OXnyJE2bNiUg4Ox9M34Xbo4cOUJsbKzZZYiIiEgVJCcn07x587O28btwEx4eDhg/nIiICJOrERERkcrIysoiNjbW9T1+Nn4XbopPRUVERCjciIiI1DKVGVKiAcUiIiLiUxRuRERExKco3IiIiIhP8bsxNyIiUnl2u52CggKzyxA/ERwcfM7LvCtD4UZERMpwOp2kpqaSkZFhdiniRwICAmjVqhXBwcEXdByFGxERKaM42ERHRxMWFqZJT6XaFU+ym5KSQosWLS7o35zCjYiIuLHb7a5g06BBA7PLET/SqFEjjhw5QmFhIUFBQVU+jgYUi4iIm+IxNmFhYSZXIv6m+HSU3W6/oOMo3IiISLl0Kkpqmqf+zSnciIiIiE9RuBERERGfonAjIiI+Y8yYMQwdOtTsMsRkCjciIiLiUxRuPKngFBzda3YVIiJSjq+++orevXtjs9lo0qQJEydOpLCw0LX9gw8+oFOnToSGhtKgQQPi4+PJyckBYN26dfTu3Zs6depQr149+vfvz8GDB836KHIOmufGUzIOwStdICAInkqBAKvZFYmIeITT6eRUwYVdmltVoUFWj1xBc/jwYW644QbGjBnDokWL2LNnD+PGjSMkJIRp06aRkpLCyJEjmTVrFsOGDePkyZN88803OJ1OCgsLGTp0KOPGjePf//43+fn5bNiwQVeTeTGFG0+JaA6BIVCQC8cPQMNLzK5IRMQjThXYaT/lM1Pee9f0QYQFX/hX1euvv05sbCxz5szBYrHQtm1bjhw5whNPPMGUKVNISUmhsLCQW265hZYtWwLQqVMnAI4fP05mZiY33ngjrVu3BqBdu3YXXJNUH52W8pSAAGjU1lhO32VuLSIi4mb37t307dvXrbelf//+ZGdn89tvv9GlSxeuvvpqOnXqxG233cb8+fM5ceIEAPXr12fMmDEMGjSIIUOG8Morr5CSkmLWR5FKUM+NJ0W3hyNbIG0XtL/Z7GpERDwiNMjKrumDTHvvmmC1Wlm7di3ff/89n3/+Oa+++ipPPfUUP/74I61ateLtt9/m4YcfZs2aNSxdupSnn36atWvXctlll9VIfXJ+1HPjSTHtjWf13IiID7FYLIQFB5ry8NS4lnbt2rF+/XqcTqdr3XfffUd4eDjNmzd3fc7+/fvzzDPPsHXrVoKDg1m2bJmrfbdu3Zg0aRLff/89HTt2ZPHixR6pTTxPPTeeFF10DlbhRkTENJmZmWzbts1t3R//+Edmz57NhAkTeOihh9i7dy9Tp04lISGBgIAAfvzxRxITE7n22muJjo7mxx9/5OjRo7Rr145ff/2VefPmcdNNN9G0aVP27t3Lzz//zKhRo8z5gHJOCjeeFF3Uc3P8gHFZeFCoufWIiPihdevW0a1bN7d19957L6tWreIvf/kLXbp0oX79+tx77708/fTTAERERPD1118ze/ZssrKyaNmyJS+99BLXX389aWlp7Nmzh3feeYfff/+dJk2aMH78eP70pz+Z8fGkEizO0n10fiArK4vIyEgyMzOJiIjw7MGdTliZAFGtoOdYsIV79vgiIjXg9OnT/Prrr7Rq1YqQkBCzyxE/crZ/e+fz/a2eG0+yWODGf5hdhYiIiF/TgGIRERHxKQo3nmYvhPQ9kPSt2ZWIiIj4JYUbTzu8CV7vAx+OM7sSERERv6Rw42nFl4OfPAKnTphbi4iIiB9SuPG0kEjjPlNgnJ4SERGRGqVwUx1cMxXvNLcOERERP6RwUx1cMxXvNrcOERERP2R6uHnttdeIi4sjJCSEPn36sGHDhrO2nz17NpdeeimhoaHExsby2GOPcfr06RqqtpKiOxjPCjciIiI1ztRws3TpUhISEpg6dSpbtmyhS5cuDBo0iPT09HLbL168mIkTJzJ16lR2797NggULWLp0KU8++WQNV34OxT03aTuNWYtFRERqWFJSEhaLpcx9tvyBqeHm5ZdfZty4cYwdO5b27dszd+5cwsLCeOutt8pt//3339O/f3/uvPNO4uLiuPbaaxk5cuQ5e3tqXKNL4aqn4ObXwOkwuxoREb+yfv16rFYrgwcPNruUGmGxWMo8BgwYQGxsLCkpKXTs2BEw7rllsVjIyMgwt+AaYFq4yc/PZ/PmzcTHx5cUExBAfHw869evL3effv36sXnzZleYOXDgAKtWreKGG26okZorLdAGA/8K7W6EAKvZ1YiI+JUFCxYwYcIEvv76a44cOVKt7+V0OiksLKzW96iMt99+m5SUFNfjk08+wWq10rhxYwID/e9OS6aFm2PHjmG324mJiXFbHxMTQ2pqarn73HnnnUyfPp0BAwYQFBRE69atufLKK896WiovL4+srCy3h4iI+Kbs7GyWLl3KAw88wODBg1m4cKFr25133smIESPc2hcUFNCwYUMWLVoEgMPhYMaMGbRq1YrQ0FC6dOnCBx984Gpf3PuxevVqevTogc1m49tvv+WXX37h5ptvJiYmhrp169KrVy+++OILt/dKSUlh8ODBhIaG0qpVKxYvXkxcXByzZ892tcnIyOC+++6jUaNGRERE8H//939s3779nJ+7Xr16NG7c2PWoX7++22mppKQkrrrqKgCioqKwWCyMGTMGgCuvvJKHH36Yv/71r9SvX5/GjRszbdo0t+Ofq67t27dz1VVXER4eTkREBD169GDTpk0AHDx4kCFDhhAVFUWdOnXo0KEDq1atOudnuhCmDyg+H+vWreOFF17g9ddfZ8uWLXz00UesXLmSZ599tsJ9ZsyYQWRkpOsRGxtbM8Xm/A57VsHe1TXzfiIi1S0/p+JHwenzaHuqcm2r4P3336dt27Zceuml3H333bz11ls4i8Y+3nXXXXz66adkZ2e72n/22Wfk5uYybNgwwPjOWLRoEXPnzmXnzp089thj3H333Xz11Vdu7zNx4kRefPFFdu/eTefOncnOzuaGG24gMTGRrVu3ct111zFkyBAOHTrk2mfUqFEcOXKEdevW8eGHHzJv3rwyY0xvu+020tPTWb16NZs3b6Z79+5cffXVHD9+vEo/j2KxsbF8+OGHAOzdu5eUlBReeeUV1/Z33nmHOnXq8OOPPzJr1iymT5/O2rVrK13XXXfdRfPmzdm4cSObN29m4sSJBAUFATB+/Hjy8vL4+uuv+emnn5g5cyZ169a9oM9zTk6T5OXlOa1Wq3PZsmVu60eNGuW86aabyt1nwIABzscff9xt3bvvvusMDQ112u32cvc5ffq0MzMz0/VITk52As7MzEyPfI4K7fzY6Zwa4XTOvaJ630dExMNOnTrl3LVrl/PUqVPuG6ZGVPz4163ubZ9rXHHbt25wbzuzVfntqqBfv37O2bNnO51Op7OgoMDZsGFD55dffun2etGiRa72I0eOdI4YMcLpdBrfF2FhYc7vv//e7Zj33nuvc+TIkU6n0+n88ssvnYBz+fLl56ylQ4cOzldffdXpdDqdu3fvdgLOjRs3urb//PPPTsD5j3/8w+l0Op3ffPONMyIiwnn69Gm347Ru3dr55ptvVvg+gDMkJMRZp04d12PZsmXOX3/91Qk4t27d6lb7iRMn3PYfOHCgc8CAAW7revXq5XziiScqXVd4eLhz4cKF5dbXqVMn57Rp0yqsv7QK/+05nc7MzMxKf3+bdiIuODiYHj16kJiYyNChQwGjOzAxMZGHHnqo3H1yc3MJCHDvbLJajTEtzgquSrLZbNhsNs8VXlnRRRP5Hd0LDrvG3oiIVLO9e/eyYcMGli1bBkBgYCAjRoxgwYIFXHnllQQGBnL77bfz3nvv8Yc//IGcnBw+/vhjlixZAsD+/fvJzc3lmmuucTtufn4+3bp1c1vXs2dPt9fZ2dlMmzaNlStXkpKSQmFhIadOnXL13Ozdu5fAwEC6d+/u2ufiiy8mKirK9Xr79u1kZ2fToEEDt2OfOnWKX3755ayf/R//+IfbGNYmTZpw9OjRs+5TWufOnd1eN2nSxNWrVJm6EhISuO+++3j33XeJj4/ntttuo3Xr1gA8/PDDPPDAA3z++efEx8czfPjwMu/naaaOMkpISGD06NH07NmT3r17M3v2bHJychg7dixgdOE1a9aMGTNmADBkyBBefvllunXrRp8+fdi/fz+TJ09myJAhrpDjNeq3gsAQKDwFJ5KgQWuzKxIRuTBPnmVwruWM/wf/Zf9Z2p4xIuLRn6peUykLFiygsLCQpk2butY5nU5sNhtz5swhMjKSu+66i4EDB5Kens7atWsJDQ3luuuuA3Cdrlq5ciXNmjVzO/aZfyTXqVPH7fXjjz/O2rVr+fvf/87FF19MaGgot956K/n5+ZWuPzs7myZNmrBu3boy2+rVq3fWfRs3bszFF1/stu58wk3xKaRiFosFh8NR6bqmTZvGnXfeycqVK1m9ejVTp05lyZIlDBs2jPvuu49BgwaxcuVKPv/8c2bMmMFLL73EhAkTKl3f+TI13IwYMYKjR48yZcoUUlNT6dq1K2vWrHENMj506JBbT83TTz+NxWLh6aef5vDhwzRq1IghQ4bw/PPPm/URKhZgNS4JT9kO6bsUbkSk9guuc+421d22AoWFhSxatIiXXnqJa6+91m3b0KFD+fe//839999Pv379iI2NZenSpaxevZrbbrvN9cXevn17bDYbhw4dYuDAgef1/t999x1jxoxxjd3Jzs4mKSnJtf3SSy+lsLCQrVu30qNHD8DoKTpxouQGy927dyc1NZXAwEDi4uKq8FM4u+DgYADsdvt57VfZutq0aUObNm147LHHGDlyJG+//bbr5xEbG8v999/P/fffz6RJk5g/f77vhhuAhx56qMLTUGemxMDAQKZOncrUqVNroDIPiO5QFG52Q7shZlcjIuKzVqxYwYkTJ7j33nuJjIx02zZ8+HAWLFjA/fffDxhXTc2dO5d9+/bx5ZdfutqFh4fz+OOP89hjj+FwOBgwYACZmZl89913REREMHr06Arf/5JLLuGjjz5iyJAhWCwWJk+e7Or5AGjbti3x8fH88Y9/5I033iAoKIg///nPhIaGYrFYAIiPj6dv374MHTqUWbNm0aZNG44cOcLKlSsZNmxYmVNh56tly5ZYLBZWrFjBDTfcQGhoaKUG9p6rrg4dOvCXv/yFW2+9lVatWvHbb7+xceNGhg8fDsCjjz7K9ddfT5s2bThx4gRffvkl7dq1u6DPci616mqpWqf0TMUiIlJtFixYQHx8fJlgA0a42bRpE//73/8A48qeXbt20axZM/r37+/W9tlnn2Xy5MnMmDGDdu3acd1117Fy5UpatWp11vd/+eWXiYqKol+/fgwZMoRBgwa5ja8BWLRoETExMVxxxRUMGzaMcePGER4eTkhICGCcClq1ahVXXHEFY8eOpU2bNtxxxx0cPHiwzLQpVdGsWTOeeeYZJk6cSExMTIUdC2c6V11Wq5Xff/+dUaNG0aZNG26//Xauv/56nnnmGcDoKRo/frzr59mmTRtef/31C/48Z63ZWdFIXB+VlZVFZGQkmZmZREREVO+b7f8C/jUcGl4KD3nZLMoiIhU4ffo0v/76K61atXJ98Yrn/fbbb8TGxvLFF19w9dVXm12OVzjbv73z+f42/bSUT2vaHYYvgJgOZlciIiIm++9//0t2djadOnUiJSWFv/71r8TFxXHFFVeYXZrPUbipTmH1odOtZlchIiJeoKCggCeffJIDBw4QHh5Ov379eO+998pcqSQXTuFGRESkBgwaNIhBgwaZXYZfULipbul7jLE3kc2hw1CzqxEREfF5ulqquh38Fj5/CrYtNrsSEZHz4mfXm4gX8NS/OYWb6lZ8G4b0XebWISJSScVjQHJzc02uRPxN8YzOF3rXAZ2Wqm7Fc91kJsPpTAgpOweDiIg3sVqt1KtXz3VvobCwMNdEcyLVxeFwcPToUcLCwggMvLB4onBT3UKjILwpnDxijL9p0cfsikREzqlx48YAroAjUhMCAgJo0aLFBYdphZuaENO+KNzsVLgRkVrBYrHQpEkToqOjKSgoMLsc8RPBwcFu95SsKoWbmhDdzrhiKn232ZWIiJwXq9V6weMfRGqaBhTXhOJBxWkaVCwiIlLd1HNTEy65Fsb9Fxq1NbsSERERn6dwUxPqNDQeIiIiUu10WkpERER8isJNTdn/BaxIgJ3Lza5ERETEpync1JTkDbBpAexfa3YlIiIiPk3hpqa4bsOgy8FFRESqk8JNTXGFmz3gcJhbi4iIiA9TuKkp9S8Cqw0KciDjoNnViIiI+CyFm5piDYRGbYxl3SFcRESk2ijc1CTXqSmFGxERkeqicFOTisNN5mFz6xAREfFhmqG4JvUYDd1HQVh9sysRERHxWQo3NSk0yuwKREREfJ5OS4mIiIhPUbipaRvmw6KhsGel2ZWIiIj4JIWbmpa2Ew58Cb9tMrsSERERn6RwU9N0GwYREZFqpXBT02KKw81Oc+sQERHxUQo3Na245ybjEOSdNLcWERERH6RwU9PC6kPdxsZy+h5zaxEREfFBCjdmiG5nPOs2DCIiIh6ncGOGmA7GhH4Fp8yuRERExOdYnE6n0+wialJWVhaRkZFkZmYSERFhThGF+WANAovFnPcXERGpZc7n+1u3XzBDYLDZFYiIiPgsnZYSERERn6JwY5YVCTC7M/z6tdmViIiI+BSFG7OcTIWMg5CmK6ZEREQ8SeHGLJqpWEREpFoo3JjFNdeN7jElIiLiSQo3ZonuYDyn7waHw9xaREREfIjCjVkatIaAIMjPhsxks6sRERHxGQo3ZrEGQaNLjWWdmhIREfEYTeJnpuY9IdAGFmVMERERT1G4MdOQV8yuQERExOeoy0BERER8isKNNyjM0xVTIiIiHqJwY7b/Fw8vNIVj+8yuRERExCco3JjOAo5CzVQsIiLiIQo3ZtNMxSIiIh6lcGO26KJ7TOkGmiIiIh6hcGM21w00FW5EREQ8QeHGbMU9NyeSID/H1FJERER8gcKN2eo0hDrRgBOO7jG7GhERkVpPMxR7g7aDjRtoWm1mVyIiIlLrKdx4gyGzza5ARETEZ+i0lIiIiPgUhRtv4bDD77+YXYWIiEitp3DjDQpOw4zm8Gp3yD1udjUiIiK1msKNNwgKgTqNjGXNdyMiInJBFG68hWYqFhER8QiFG2+hmYpFREQ8QuHGW0Qr3IiIiHiCwo23KH13cKfT3FpERERqMYUbb9HgEggIhLwsyPzN7GpERERqLc1Q7C0Cg6HXfRASCdZgs6sRERGptRRuvMn1M82uQEREpNbTaSkRERHxKQo33sTpNMbbHPze7EpERERqLdPDzWuvvUZcXBwhISH06dOHDRs2nLV9RkYG48ePp0mTJthsNtq0acOqVatqqNpqdiIJ/tEBFt0M9kKzqxEREamVTA03S5cuJSEhgalTp7Jlyxa6dOnCoEGDSE9PL7d9fn4+11xzDUlJSXzwwQfs3buX+fPn06xZsxquvJrUawlBdcCeD8d1E00REZGqMDXcvPzyy4wbN46xY8fSvn175s6dS1hYGG+99Va57d966y2OHz/O8uXL6d+/P3FxcQwcOJAuXbrUcOXVJCAAotsay5rMT0REpEpMCzf5+fls3ryZ+Pj4kmICAoiPj2f9+vXl7vPJJ5/Qt29fxo8fT0xMDB07duSFF17AbrdX+D55eXlkZWW5Pbxa6cn8RERE5LyZFm6OHTuG3W4nJibGbX1MTAypqanl7nPgwAE++OAD7HY7q1atYvLkybz00ks899xzFb7PjBkziIyMdD1iY2M9+jk8znUDzZ3m1iEiIlJLmT6g+Hw4HA6io6OZN28ePXr0YMSIETz11FPMnTu3wn0mTZpEZmam65GcnFyDFVeB6x5T6rkRERGpCtMm8WvYsCFWq5W0tDS39WlpaTRu3LjcfZo0aUJQUBBWq9W1rl27dqSmppKfn09wcNmZfW02GzabzbPFV6ficHP8ABScgqBQc+sRERGpZUzruQkODqZHjx4kJia61jkcDhITE+nbt2+5+/Tv35/9+/fjcDhc6/bt20eTJk3KDTa1Ut1ouOKvMKzi3igRERGpmKmnpRISEpg/fz7vvPMOu3fv5oEHHiAnJ4exY8cCMGrUKCZNmuRq/8ADD3D8+HEeeeQR9u3bx8qVK3nhhRcYP368WR/B8ywW+L+noMsd6rURERGpAlPvLTVixAiOHj3KlClTSE1NpWvXrqxZs8Y1yPjQoUMEBJTkr9jYWD777DMee+wxOnfuTLNmzXjkkUd44oknzPoIIiIi4mUsTqfTaXYRNSkrK4vIyEgyMzOJiIgwu5zy5WXDkS1wOgva3Wh2NSIiIqY7n+9v3RXcG6XthHeGQHgThRsREZHzVKsuBfcbxRP5nUyB3OPm1iIiIlLLKNx4o5AIiCyabPDoHnNrERERqWUUbryVZioWERGpEoUbb6V7TImIiFSJwo23iulgPCvciIiInBeFG2/l6rnZCf51tb6IiMgF0aXg3qphG7hxttGD43QaMxeLiIjIOSnceKtAG/Qca3YVIiIitY5OS4mIiIhPUc+NN8tIhl8SITAUuowwuxoREZFaQT033ixlO3z6CPzwmtmViIiI1BoKN96s+Iqpo3vBYTe3FhERkVpC4cabRcUZp6QKT8PxX82uRkREpFZQuPFmAVaIbmssp+8ytxYREZFaQuHG2xXfY0ozFYuIiFSKwo23c4Ub3UBTRESkMhRuvJ1uoCkiInJeNM+Nt2veE0Z9UnIjTRERETkrhRtvFxIJFw00uwoREZFaQ6elRERExKeo56Y2+G0z7P4YGl4K3e4yuxoRERGvpp6b2iBlG3z3CuxabnYlIiIiXk/hpjYovhw8TRP5iYiInIvCTW1QfDl41m9wKsPUUkRERLydwk1tEFoPIpoZy0f3mFqKiIiIt1O4qS1cp6Y0U7GIiMjZKNzUFpqpWEREpFIUbmqL4p6bE7+aW4eIiIiX0zw3tUXbG+DRHRDZ3OxKREREvJrCTW0REmk8RERE5Kx0WkpERER8isJNbbLjI1h6N2xbbHYlIiIiXkvhpjY5uhd2fwpJ35pdiYiIiNdSuKlNYoqumErXbRhEREQqonBTmxRfDp6+BxwOc2sRERHxUgo3tUn9i8Bqg8JTmu9GRESkAgo3tUmAFRpdaixrpmIREZFyKdzUNtEadyMiInI2Cje1TUx7CAyB/GyzKxEREfFKmqG4tun9R+j7kHGKSkRERMpQuKltgkLNrkBERMSr6bSUiIiI+BSFm9roq1nwRn/jdgwiIiLiRuGmNjqZAmk7IPV/ZlciIiLidRRuaiPX5eCa60ZERORMCje1UXG4SdNcNyIiImeqUrhJTk7mt99+c73esGEDjz76KPPmzfNYYXIW0e2M58xDcDrL3FpERES8TJXCzZ133smXX34JQGpqKtdccw0bNmzgqaeeYvr06R4tUMoRVh/CmxjLR/eaW4uIiIiXqVK42bFjB7179wbg/fffp2PHjnz//fe89957LFy40JP1SUWKe2/Sd5pbh4iIiJep0iR+BQUF2Gw2AL744gtuuukmANq2bUtKSornqpOKNe4MmYchQPMwioiIlFalnpsOHTowd+5cvvnmG9auXct1110HwJEjR2jQoIFHC5QKxE+DhzZAt7vNrkRERMSrVCnczJw5kzfffJMrr7ySkSNH0qVLFwA++eQT1+kqqWYWi9kViIiIeCWL0+l0VmVHu91OVlYWUVFRrnVJSUmEhYURHR3tsQI9LSsri8jISDIzM4mIiDC7nAvncABO3UhTRER82vl8f1ep5+bUqVPk5eW5gs3BgweZPXs2e/fu9epg43P+MwZmNIekb8yuRERExGtUKdzcfPPNLFq0CICMjAz69OnDSy+9xNChQ3njjTc8WqCchb0ACnI0U7GIiEgpVQo3W7Zs4fLLLwfggw8+ICYmhoMHD7Jo0SL++c9/erRAOQvXTMW6HFxERKRYlcJNbm4u4eHhAHz++efccsstBAQEcNlll3Hw4EGPFihn4ZrrRj03IiIixaoUbi6++GKWL19OcnIyn332Gddeey0A6enpvjFIt7aI6WA8H91TNLBYREREqhRupkyZwuOPP05cXBy9e/emb9++gNGL061bN48WKGdR/yKwBkN+tnGfKREREanaDMW33norAwYMICUlxTXHDcDVV1/NsGHDPFacnIM1CBpeCmk/GaemouLMrkhERMR0VZ67v3HjxjRu3Nh1d/DmzZtrAj8zXDQQIptDcF2zKxEREfEKVTot5XA4mD59OpGRkbRs2ZKWLVtSr149nn32WRwa+1GzBj0Pdy6BVpebXYmIiIhXqFLPzVNPPcWCBQt48cUX6d+/PwDffvst06ZN4/Tp0zz//PMeLVJERESksqp0+4WmTZsyd+5c193Ai3388cc8+OCDHD582GMFeprP3X4BwOmE7DQIawhW3SVcRER8T7XffuH48eO0bdu2zPq2bdty/PjxqhxSLsQ/u8JLl8KxfWZXIiIiYroqhZsuXbowZ86cMuvnzJlD586dL7goOU91iu7nlb7L3DpERES8QJXOYcyaNYvBgwfzxRdfuOa4Wb9+PcnJyaxatcqjBUolxLSH3zZopmIRERGq2HMzcOBA9u3bx7Bhw8jIyCAjI4NbbrmFnTt38u6773q6RjmX4ntMqedGRESkagOKK7J9+3a6d++O3W731CE9zicHFP/6DbxzozGJ3yPbza5GRETE46p9QLF4meIbaJ5IgrxsU0sRERExm1eEm9dee424uDhCQkLo06cPGzZsqNR+S5YswWKxMHTo0Oot0NvVaVgyqPjoXnNrERERMZnp4Wbp0qUkJCQwdepUtmzZQpcuXRg0aBDp6eln3S8pKYnHH3+cyy/XzLwAdL0TLhsPIZFmVyIiImKq8xpzc8stt5x1e0ZGBl999dV5jbnp06cPvXr1cl1a7nA4iI2NZcKECUycOLHcfex2O1dccQX33HMP33zzDRkZGSxfvrxS7+eTY25ERER83Pl8f5/XpeCRkWfvFYiMjGTUqFGVPl5+fj6bN29m0qRJrnUBAQHEx8ezfv36CvebPn060dHR3HvvvXzzzTdnfY+8vDzy8vJcr7Oysipdn4iIiNQ+5xVu3n77bY+++bFjx7Db7cTExLitj4mJYc+ePeXu8+2337JgwQK2bdtWqfeYMWMGzzzzzIWWWjucOgFH90GLPmZXIiIiYhrTx9ycj5MnT/KHP/yB+fPn07Bhw0rtM2nSJDIzM12P5OTkaq7SJPm5MLMVvHUt5PxudjUiIiKmMfUuiw0bNsRqtZKWlua2Pi0tjcaNG5dp/8svv5CUlMSQIUNc6xwOBwCBgYHs3buX1q1bu+1js9mw2WzVUL2XCQ6DqJbG5eDpu6CVBlqLiIh/MrXnJjg4mB49epCYmOha53A4SExMdN3WobS2bdvy008/sW3bNtfjpptu4qqrrmLbtm3ExsbWZPneRzMVi4iImNtzA5CQkMDo0aPp2bMnvXv3Zvbs2eTk5DB27FgARo0aRbNmzZgxYwYhISF07NjRbf969eoBlFnvl6Lbw95VCjciIuLXTA83I0aM4OjRo0yZMoXU1FS6du3KmjVrXIOMDx06REBArRoaZJ7imYrTFG5ERMR/efTeUrWBT89zk7YL3ugLweEwKRksFrMrEhER8QjdW8pfNbgYAoIg/yRk+uhVYSIiIudg+mkp8aDAYLjiLxBWH4Lrml2NiIiIKRRufM2VT5hdgYiIiKl0WkpERER8isKNrynMh8NbYPenZlciIiJiCp2W8jUnj8D8q8AaDE8eAWuQ2RWJiIjUKPXc+JrIFhBUB+z5cPyA2dWIiIjUOIUbXxMQUGoyv53m1iIiImIChRtfVBxu0nebW4eIiIgJFG58UUwH41n3mBIRET+kcOOLXD03CjciIuJ/FG58UXRRz83xXyE/19xaREREapguBfdFdRvB9bOK7jWlX7GIiPgXffP5qj5/MrsCERERU+i0lIiIiPgU9dz4qtzj8Mt/ofA0dLvb7GpERERqjMKNr/p9P3x4L4Q3UbgRERG/otNSvqpRW+P5ZIrRiyMiIuInFG58VUiEcZ8p0EzFIiLiVxRufFlMe+NZk/mJiIgfUbjxZZqpWERE/JDCjS8rnqlYp6VERMSPKNz4suKem7Rd4HSaW4uIiEgN0aXgvqxhG7hjMUS3N7sSERGRGqNw48sCg6HtYLOrEBERqVE6LSUiIiI+RT03vu7Yz7BzOYTWg97jzK5GRESk2qnnxtcd2wdfPgdbFpldiYiISI1QuPF1xVdMHd0LDru5tYiIiNQAhRtfVy8OgsLAngfHfzW7GhERkWqncOPrAgJKbqKZvtPcWkRERGqAwo0/KJ7nRjMVi4iIH1C48QeumYrVcyMiIr5P4cYfFN8d/NjP5tYhIiJSAzTPjT+I7QMP/gANLja7EhERkWqncOMPguuUnJoSERHxcTotJSIiIj5F4cZfHPgKlj0AP84zuxIREZFqpXDjL47/AtsXw8+fm12JiIhItVK48ReuuW52mVuHiIhINVO48RfFA4qzDsOpDFNLERERqU4KN/4iJBIimhvLmqlYRER8mMKNPynuvdGpKRER8WEKN/4kRuNuRETE9ync+JPo9oBFY25ERMSnaYZif9LuJuMRHGZ2JSIiItVG4cafKNSIiIgf0GkpERER8SkKN/5m80JYMAg2LjC7EhERkWqhcONvTqZC8g9weLPZlYiIiFQLhRt/U3wbhrSd5tYhIiJSTRRu/E1xuDm6Fxx2c2sRERGpBgo3/qZ+KwgMgcJTcCLJ7GpEREQ8TuHG3wRYodGlxrJmKhYRER+kcOOPik9N6QaaIiLigxRu/FF0e4hoZvTiiIiI+BjNUOyP+k2A/g+bXYWIiEi1UM+NP7JYzK5ARESk2ijc+Dun0+wKREREPErhxl+teRL+dgn89B+zKxEREfEohRt/VXgactI1U7GIiPgchRt/Fd3OeNbl4CIi4mMUbvxVTAfjWRP5iYiIj1G48VfFPTeZyXA6y9xaREREPEjhxl+FRkF4U2P56B5zaxEREfEghRt/Vtx7o0HFIiLiQzRDsT9r0Rfs+UYvjoiIiI+wOJ3+NYtbVlYWkZGRZGZmEhERYXY5IiIiUgnn8/2t01IiIiLiUxRuBPJOQmGe2VWIiIh4hFeEm9dee424uDhCQkLo06cPGzZsqLDt/Pnzufzyy4mKiiIqKor4+PiztpdzeGcIzGgOB783uxIRERGPMD3cLF26lISEBKZOncqWLVvo0qULgwYNIj09vdz269atY+TIkXz55ZesX7+e2NhYrr32Wg4fPlzDlfuIkEjjWTMVi4iIjzB9QHGfPn3o1asXc+bMAcDhcBAbG8uECROYOHHiOfe32+1ERUUxZ84cRo0adc72GlB8hi9fgK9mQre74ebXzK5GRESkXLVmQHF+fj6bN28mPj7etS4gIID4+HjWr19fqWPk5uZSUFBA/fr1q6tM3xbd3nhWz42IiPgIU+e5OXbsGHa7nZiYGLf1MTEx7NlTuVlzn3jiCZo2beoWkErLy8sjL69ksGxWlm414MYVbvaAwwEBpp+pFBERuSC1+pvsxRdfZMmSJSxbtoyQkJBy28yYMYPIyEjXIzY2toar9HL1LwKrDQpyIOOg2dWIiIhcMFPDTcOGDbFaraSlpbmtT0tLo3Hjxmfd9+9//zsvvvgin3/+OZ07d66w3aRJk8jMzHQ9kpOTPVK7z7AGQqM2xrJOTYmIiA8wNdwEBwfTo0cPEhMTXescDgeJiYn07du3wv1mzZrFs88+y5o1a+jZs+dZ38NmsxEREeH2kDO0uwm6j4LwmHO3FRER8XKm31sqISGB0aNH07NnT3r37s3s2bPJyclh7NixAIwaNYpmzZoxY8YMAGbOnMmUKVNYvHgxcXFxpKamAlC3bl3q1q1r2ueo1Qb+1ewKREREPMb0cDNixAiOHj3KlClTSE1NpWvXrqxZs8Y1yPjQoUMElBrk+sYbb5Cfn8+tt97qdpypU6cybdq0mixdREREvJDp89zUNM1zU4GC03BsH0S3A2uQ2dWIiIi4qTXz3IiXcDrh5bbw5uVw7GezqxEREbkgCjcCFgs0LL5iape5tYiIiFwghRsxuCbzU7gREZHaTeFGDMXhJk3hRkREajeFGzHEqOdGRER8g8KNGBq1M54zDkLeSXNrERERuQAKN2Ko0wDqFs1QfHSvubWIiIhcANMn8RMvctkDxnNd3YZBRERqL4UbKTHgMbMrEBERuWA6LSUiIiI+ReFGSjgcxgzFu1eYXYmIiEiV6bSUlCg8BXN6AU54fD/UbWR2RSIiIudNPTdSIrgORMUZy5rvRkREaimFG3Hnug3DbnPrEBERqSKFG3Hnmql4p7l1iIiIVJHCjbiLLpqpWD03IiJSSynciLuYjsbzbxth5ePm1iIiIlIFCjfirtGlcNmDxnL9i8ytRUREpAp0KbiUdd0M6DISGrUtWffzF3DiV+gxBqxBppUmIiJyLuq5kfI16QyBwcayvQDWTIRVj8Prl8GeleB0mlufiIhIBRRupBIscNn9ENYQft8PS+6EhYPh8BazCxMRESlD4UbOzRoIve6Dh7fC5X+GwBA4+B3Mvwo+HAcZyWZXKCIi4qJwI5UXEgFXT4GHNkHnO4x1P72v2YxFRMSrKNzI+asXC7e8CX9cB/0fgUuuLdmW8j9jjI6IiIhJdLWUVF3TbsajWO5xeOdGqBMN10yHS68Hi8W8+kRExC+p50Y85+heCAiC33+GJSNh4Y0adCwiIjVO4UY8p2VfY9DxgISiQcffGoOOP/qjBh2LiEiNUbgRzwqJgPip7oOO/7cUXutjnLYSERGpZgo3Uj1KDzpuOQC6jICw+iXbNQmgiIhUE4UbqV5Nu8GYFXDdiyXr0nYVzXS8SiFHREQ8TuFGqp/FAoG2ktffvARH9xiDjt8ZAke2mlebiIj4HIUbqXk3vmwMOrbaIOkbmHelMeg48zezKxMRER+gcCM1LyTSGHQ8YTN0HmGs+99SeLUHfPOyubWJiEitp3Aj5qkXC7fMKxl0XHja/fSViIhIFWiGYjFf8aDjn9fCRQNL1h/4Cgpyoc11mulYREQqTeFGvIPFAm1K3aPKXgAr/2zMdhx3OVz7HDTtalp5IiJSe+i0lHgnRyG0HVxq0PFA+OhPGnQsIiLnpHAj3ikoFK55BiZsgk63G+v+t8QYdPzFM3A6y9z6RETEaynciHer1wKGz4dxX0LL/sag429fhoPfm12ZiIh4KY25kdqhWXcYsxL2roJ9a6DNoJJtGYcgMlaDjkVEBFDPjdQmFosxDuemV0uCTO5xmDvAmOk4Zbu59YmIiFdQuJHaLXkDFJw2Bh2/ORCW3a9BxyIifk7hRmq3S68rNejYCdv/bQw6TpwOeSfNrk5ERExgcTr967bMWVlZREZGkpmZSUREhNnliCcd3gyfPQ2HigYbhzeBhzaBra7xesdHEFzXeG0LL1qOMF5rZmQREa92Pt/fGlAsvqNZDxi7CvashLVToNUVJcGmMA8+GFvxvm1vhDveK3m98EYj8LjCUETRcjg0vAQuvb6kbeoO49L14sAUFKrBzSIiJlK4Ed9isUC7G42rqQpOlay35xv3r8o/CXnZkJ9tnLYqyDW2B4WWtC3MN8bwVKTNde7h5v9dbVyi7qrBagSi4HBodTkMm1uybfVEwFkSlIrb2cIhvLFxVVix/FwFJRGRKlC4Ed9kDTIexWzhMHZl2XYOuxF0Sp+dtQTA7e8a4ac4BJVebtzZff/QqKLAVDTGx2mH05nGI/e4+/ttXgiFpyhXi75wz5qS1//sCtnp7r1BlgDAYtyKYuS/S9ouGATZacZ2i8VoU7zc4GL3Xqmld0NGctl2WCCiKdz+TknbTx+B4wfc2xXXEBplzEFULHE6HN3r3qZ4n6BQuPm1krY7PoKsIxASYfSKhUQYd4u3RRrLdRop1IlIlSnceFBufiFhwfqR1ioBVuNLtTRrILS/qfL7/3mPsexwQEGOEXTyThphJ7BUj5DTCQP/WhSSSrUpXo5u537svJOA02iTf8bg6Jxm7q8zDsLJlPJrtFjdX6ftguO/lN82qpX76982Q9pP5betG+P+Ouk7SP6h/La2CPdws2URHPiy/LZYYMrxknCzeqJx3JDIkiBUHIJCIqHXfSVBNiMZHAUl20sHXBHxG/om9pCUzFMMmPkl7ZtE0DMuip4t69MzLoqYiBCzS5OaEhBQdKopHGhSdrvFApcnVP54j/9cEoQKTxX1LjmN56Aw97Z3LDZOvbnaOEqWg+q4t73pVcjPKdvO6XA/PQcQPw1OZxhtnI6S93c6yg7C7jcBsm8vaof7PmeGjIuuhDoNi3q4siAvy3g+nWkExoBSF3Ie3QNHtlbwQ7JA7z+VvPz8adi1vOR1UFipQBQBoz+F4KKf3a6P4di+kiBkKwpLxcuRzY1aPMXpNG4Iaw0qCW45v8Op48aYMHu+8SjMM9rZ8+Ciq0rqPfQjHNlS1Cbf2F56eeATxqlNgP+9D9uXlBzzzH1GLoGYDkbbbf+G72aX+jmFu//MOt8OUXFG2+x0yDpcNBC/qI0G44sXUrjxkP/9lond4eSnw5n8dDiTt79LAiC2fii9WtanR1HguSS6LgEB6m6XSrAVDWYOr0Tb0mN1ziWuf+XbXhJf+bbtbqx82wGPVrzN4XB/fc0zkPWnkvCTVyoQFea7B6GAQCPMFeQYrwtyjUd2qvE6sNQfGzs+cg9CZ3riIITWM5a/mAb7Piv5Qg8KKwogRYHhzvdLguEX04xjnxlU7PnG9sf3Q91GxvK6F2Dj/6u4hoe3Qf2i3rS9K+G7Vypu2+u+knBzIgl+Say4bX5OyXLWb0aArEjLfiXhZtfHsOpx9+1WmxGIQiKM4Bw3wFifvAF2fHhGWAovCZMNLzFObYpUA4UbDxnUoTHrJ/0fm5JOsCnpOJsOnmB3ShbJx0+RfPwwH209DEBESCA94+rTo2UUveLq07l5JCFBHvzrUKS2Czhj+q0mXYxHZdy6wHi2Fxb1BmWWPOfnuB+79VXGl23pXqPi5bysoh64IieSIH1Xxe9beLok3OQeN04TVsSeV7IcXNf4sg8MBmvRI9BWNGbM5t5z1LgzdBx+RrtSy2ENStpeer1xSxJrUNl21mBodGlJ2y53QvPepT77SfefXWTzkrYBgRDetOSUavHnyc2D3GPuY9dStsOPpQbTn+mOxcaM4wA/fQArEkp6i4rDUvFyj9HQtJvRNvOwcWy3XqbIos9mM04ri9/TPDfV6OTpArYlZ7CxKPBsPZTBqQK7W5sgq4VOzSLpGVefni2j6NEyigZ11c0r4lWO7Td6OIpDUMEp9+DQ9kYIKuoV+v0XI+CUDiylQ4stsmyAq40c9lJBqCgUxbQvGcOWvNG4F1xe0bbi0Fjcftib0LKv0Xbj/4OVf674vUa8V9Iz+L//wEf3Vdz2lv8HnW8zln9eCysecw92pZ8vewAuLuqdTN9j1FFeO2uwcePemPZG29zjxilCq6389iH1SqahqGlOp/G7gZKg57AbFxw4Co2eRIfdGJvmKDT+EAirX9JDWJgPv/zXfbtruQDqX2T8YQDG629edt/usEOD1tB7nMc/mua58RLhIUFcfkkjLr/E6IIusDvYnZJl9O4cPM6mpBOkn8xjy6EMthzKYF7Rfhc1qkPPllGuwNOqYR0sunJExDwNLzYeldGgtfHwdQFW47Rd8am7M8X2Mh6V0XkExF1RFJYyz+hBynIfbG+ra8xp5QpLpaZ0APfxXXlZkJlc8ft2HF6yfCIJNs6vsCk3/L0k3KTthH8Nr7ht/DQY8JixfHgLLLi2gtBkg173QM97jLbHf4VVfzGCgissFIcLO3T7A1x2f1HbA8ZxXQGkVAgBuOxBuG6GsXwyFf7RvuJ6u4+Gm/5pLBfkwL9HVNy2020l4cbpNE6tnumiK6sl3JwPhZsaFGQNoHPzenRuXo97BrTC6XSSfPwUmw4eZ2PSCTYfPM6+tGwOHM3hwNEc3t9k3COpQZ1g12msHnFRdGwaSXCgD/zlJyICxumlRpUZXIZxyq30PFNgfLnb84wxTqUH27f+Pxj335LB1K7nojFQLS4raVv/IrjiLyXb3J7zSno2wDgF2biT+/FKty89tqswzwgd+QXlf56c30uWC3Jh/9qKP/uZV0TmHK24bXHIAeN0osVqPFuDigbtF02XERDoHlCtNiM8BgQabQKsJe0CAktOD4KxvsfYou2l2ta/qOK6aohOS3mZjNx8thw6YYSdpBNs+y2D/EL3AZa2wAC6xNajV9Eg5e4toogM0yWvIiJepzDPCCEVhaaoViU9fadOwJ5V7gGkdCCp17KkbWG+cbVf6eDhahtoBLAzr36s5c7n+1vhxsvlFdrZcTjLNUh5U9JxTuS6/wVgsUCb6HDjEvSiwNM8KlSnskRExGco3JxFbQs3Z3I6nRw4lmOEnaQTbDp4gl+P5ZRpFxNhc43Z6RVXn7aNwwm06lSWiIjUTgo3Z1Hbw015jp7MY/NBY8zOxqQT7DicSaHD/ddaJ9hKtxZRrrE7XVvUo65NQ65ERKR2ULg5C18MN2c6lW9n+28ZrlNZmw+e4OTpQrc2ARZo3zTCNZNyz5b1aRyp2ZRFRMQ7KdychT+EmzM5HE72pZ8sGqRs9O4czih788bmUaGuS9AvalSHOsGB1LFZqWMLJCw4kDrBVp3aEhERUyjcnIU/hpvypGSeYlOS0auzMek4u1OycFTiX0JwYAB1bYGEBVvPCD/FrwMJs5Us1wm2Elb0bLw2thcfIyw4EKtuRyEiIuegcHMWCjfly84rZOuhE67Ak5Z1mpy8QnLy7eTkFZYZw+NJIUHFgakoJNlKBaPgQOraSgKS8do9QLn2KXoODbLq/l0iIj5GMxTLeatrC3SbTflM+YWOorBTSG5R4MnJsxe9LiQ7z05uURjKLWqXk2cnN7+kXU6esW920bO9KDCdLnBwuiAfyPfY5ykOPMHWAAICIMBiKXqULFuKl4u2W9y2c8brUu0t5bQPKG7vvk/Z7ZU8nsX9eJai18UsFrBgKbVcsh6MbaVnAije1+LWpmSb27py25b/XsXrsZxxvDPrOaNezmh7Zt3u+7u/d7mfpfj4pT7Hme3K+wxY3H9Wxfu5vy5p7F5bqd8H7s6chcFSqsXZZmg4n/3Oq+1Z9itb/dnrPNufDRVNP1HRPmf9WZxnXb7CVz5fcGAA0eHmjeNUuJFKCQ4MIDgwmKg6wR45ntPpJK/QURKU3MJQyXJ2qYBkvC4JV6X3zS0KUMUdTLn5dnLz7WcvQkREqkX3FvX46MH+pr2/wo2YwmKxEBJkJSTISn0PBqbTBQ5X2MnOKyTf7sDhdOJ0OnE4jcHVDiclr53Oou3Fy7i3d5Zu78Th4Kzt7Y7zPJ6z1PEcZ29ffALZSell3Nbjtt5ZThv39ZR3TGfRscrs5/pJV3i88ta7H6fs+5Tep9x6io7lpPR+JS/c1595/JJ/G5zRrnSb8n8mZT/bmT+XM5fL4/beZbaVWj5jq/u2ivc7s8WZ20q/PHMUQkWlV/SZzjaKocItFR2rwiNV/D7nW68nnfn7qZb38KFBIkEmX3yicCM+w2KxEBpsJTTYCibdkFdERMyn63pFRETEpyjciIiIiE9RuBERERGfonAjIiIiPkXhRkRERHyKV4Sb1157jbi4OEJCQujTpw8bNmw4a/v//Oc/tG3blpCQEDp16sSqVatqqFIRERHxdqaHm6VLl5KQkMDUqVPZsmULXbp0YdCgQaSnp5fb/vvvv2fkyJHce++9bN26laFDhzJ06FB27NhRw5WLiIiINzL93lJ9+vShV69ezJkzBwCHw0FsbCwTJkxg4sSJZdqPGDGCnJwcVqxY4Vp32WWX0bVrV+bOnXvO99O9pURERGqf8/n+NrXnJj8/n82bNxMfH+9aFxAQQHx8POvXry93n/Xr17u1Bxg0aFCF7fPy8sjKynJ7iIiIiO8yNdwcO3YMu91OTEyM2/qYmBhSU1PL3Sc1NfW82s+YMYPIyEjXIzY21jPFi4iIiFcyfcxNdZs0aRKZmZmuR3JystkliYiISDUy9d5SDRs2xGq1kpaW5rY+LS2Nxo0bl7tP48aNz6u9zWbDZrN5pmARERHxeqb23AQHB9OjRw8SExNd6xwOB4mJifTt27fcffr27evWHmDt2rUVthcRERH/YvpdwRMSEhg9ejQ9e/akd+/ezJ49m5ycHMaOHQvAqFGjaNasGTNmzADgkUceYeDAgbz00ksMHjyYJUuWsGnTJubNm2fmxxAREREvYXq4GTFiBEePHmXKlCmkpqbStWtX1qxZ4xo0fOjQIQICSjqY+vXrx+LFi3n66ad58sknueSSS1i+fDkdO3as1PsVX/muq6ZERERqj+Lv7crMYGP6PDc17bffftMVUyIiIrVUcnIyzZs3P2sbvws3DoeDI0eOEB4ejsVi8eixs7KyiI2NJTk5WRMEegH9PryLfh/eRb8P76Pfydk5nU5OnjxJ06ZN3c7olMf001I1LSAg4JyJ70JFREToH6YX0e/Du+j34V30+/A++p1ULDIyslLtfH6eGxEREfEvCjciIiLiUxRuPMhmszF16lRNGugl9PvwLvp9eBf9PryPfiee43cDikVERMS3qedGREREfIrCjYiIiPgUhRsRERHxKQo3IiIi4lMUbjzktddeIy4ujpCQEPr06cOGDRvMLslvzZgxg169ehEeHk50dDRDhw5l7969ZpclRV588UUsFguPPvqo2aX4rcOHD3P33XfToEEDQkND6dSpE5s2bTK7LL9kt9uZPHkyrVq1IjQ0lNatW/Pss89W6v5JUjGFGw9YunQpCQkJTJ06lS1bttClSxcGDRpEenq62aX5pa+++orx48fzww8/sHbtWgoKCrj22mvJyckxuzS/t3HjRt588006d+5sdil+68SJE/Tv35+goCBWr17Nrl27eOmll4iKijK7NL80c+ZM3njjDebMmcPu3buZOXMms2bN4tVXXzW7tFpNl4J7QJ8+fejVqxdz5swBjPtXxcbGMmHCBCZOnGhydXL06FGio6P56quvuOKKK8wux29lZ2fTvXt3Xn/9dZ577jm6du3K7NmzzS7L70ycOJHvvvuOb775xuxSBLjxxhuJiYlhwYIFrnXDhw8nNDSUf/3rXyZWVrup5+YC5efns3nzZuLj413rAgICiI+PZ/369SZWJsUyMzMBqF+/vsmV+Lfx48czePBgt/9WpOZ98skn9OzZk9tuu43o6Gi6devG/PnzzS7Lb/Xr14/ExET27dsHwPbt2/n222+5/vrrTa6sdvO7G2d62rFjx7Db7cTExLitj4mJYc+ePSZVJcUcDgePPvoo/fv3p2PHjmaX47eWLFnCli1b2Lhxo9ml+L0DBw7wxhtvkJCQwJNPPsnGjRt5+OGHCQ4OZvTo0WaX53cmTpxIVlYWbdu2xWq1Yrfbef7557nrrrvMLq1WU7gRnzZ+/Hh27NjBt99+a3Ypfis5OZlHHnmEtWvXEhISYnY5fs/hcNCzZ09eeOEFALp168aOHTuYO3euwo0J3n//fd577z0WL15Mhw4d2LZtG48++ihNmzbV7+MCKNxcoIYNG2K1WklLS3Nbn5aWRuPGjU2qSgAeeughVqxYwddff03z5s3NLsdvbd68mfT0dLp37+5aZ7fb+frrr5kzZw55eXlYrVYTK/QvTZo0oX379m7r2rVrx4cffmhSRf7tL3/5CxMnTuSOO+4AoFOnThw8eJAZM2Yo3FwAjbm5QMHBwfTo0YPExETXOofDQWJiIn379jWxMv/ldDp56KGHWLZsGf/9739p1aqV2SX5tauvvpqffvqJbdu2uR49e/bkrrvuYtu2bQo2Nax///5lpkbYt28fLVu2NKki/5abm0tAgPtXsdVqxeFwmFSRb1DPjQckJCQwevRoevbsSe/evZk9ezY5OTmMHTvW7NL80vjx41m8eDEff/wx4eHhpKamAhAZGUloaKjJ1fmf8PDwMuOd6tSpQ4MGDTQOygSPPfYY/fr144UXXuD2229nw4YNzJs3j3nz5pldml8aMmQIzz//PC1atKBDhw5s3bqVl19+mXvuucfs0mo1XQruIXPmzOFvf/sbqampdO3alX/+85/06dPH7LL8ksViKXf922+/zZgxY2q2GCnXlVdeqUvBTbRixQomTZrEzz//TKtWrUhISGDcuHFml+WXTp48yeTJk1m2bBnp6ek0bdqUkSNHMmXKFIKDg80ur9ZSuBERERGfojE3IiIi4lMUbkRERMSnKNyIiIiIT1G4EREREZ+icCMiIiI+ReFGREREfIrCjYiIiPgUhRsRERHxKQo3IuKVjh49ygMPPECLFi2w2Ww0btyYQYMG8d133wHGTNTLly83t0gR8Uq6t5SIeKXhw4eTn5/PO++8w0UXXURaWhqJiYn8/vvvZpcmIl5Ot18QEa+TkZFBVFQU69atY+DAgWW2x8XFcfDgQdfrli1bkpSUBMDHH3/MM888w65du2jatCmjR4/mqaeeIjDQ+FvOYrHw+uuv88knn7Bu3TqaNGnCrFmzuPXWW2vks4lI9dNpKRHxOnXr1qVu3bosX76cvLy8Mts3btwIGDdDTUlJcb3+5ptvGDVqFI888gi7du3izTffZOHChTz//PNu+0+ePJnhw4ezfft27rrrLu644w52795d/R9MRGqEem5ExCt9+OGHjBs3jlOnTtG9e3cGDhzIHXfcQefOnQGjB2bZsmUMHTrUtU98fDxXX301kyZNcq3717/+xV//+leOHDni2u/+++/njTfecLW57LLL6N69O6+//nrNfDgRqVbquRERrzR8+HCOHDnCJ598wnXXXce6devo3r07CxcurHCf7du3M336dFfPT926dRk3bhwpKSnk5ua62vXt29dtv759+6rnRsSHaECxiHitkJAQrrnmGq655homT57Mfffdx9SpUxkzZky57bOzs3nmmWe45ZZbyj2WiPgH9dyISK3Rvn17cnJyAAgKCsJut7tt7969O3v37uXiiy8u8wgIKPnf3Q8//OC23w8//EC7du2q/wOISI1Qz42IeJ3ff/+d2267jXvuuYfOnTsTHh7Opk2bmDVrFjfffDNgXDGVmJhI//79sdlsREVFMWXKFG688UZatGjBrbfeSkBAANu3b2fHjh0899xzruP/5z//oWfPngwYMID33nuPDRs2sGDBArM+roh4mAYUi4jXycvLY9q0aXz++ef88ssvFBQUEBsby2233caTTz5JaGgon376KQkJCSQlJdGsWTPXpeCfffYZ06dPZ+vWrQQFBdG2bVvuu+8+xo0bBxgDil977TWWL1/O119/TZMmTZg5cya33367iZ9YRDxJ4UZE/Ep5V1mJiG/RmBsRERHxKQo3IiIi4lM0oFhE/IrOxIv4PvXciIiIiE9RuBERERGfonAjIiIiPkXhRkRERHyKwo2IiIj4FIUbERER8SkKNyIiIuJTFG5ERETEpyjciIiIiE/5/0LUlE2TVy5JAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10: Final particle fitness: 0.027720501963114052\n",
      "Mean Test Accuracy over 10 runs: 69.14% Â± 2.40%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate fitness of a Pso tentatives times\n",
    "mlp = Sequential(\n",
    "    Linear(size_input=train_features.shape[1], size_hidden=12),\n",
    "    ActivationReLU(),\n",
    "    Linear(size_input=12, size_hidden=12),\n",
    "    ActivationReLU(),\n",
    "    Linear(size_input=12, size_hidden=1),\n",
    ")\n",
    "\n",
    "swarm_size = 20\n",
    "epochs = 60\n",
    "accel_coeff = AccelerationCoefficients(\n",
    "        inertia_weight=0.68,\n",
    "        cognitive_weight=2.80,\n",
    "        social_weight=0.88,\n",
    "        global_best_weight=0.96,\n",
    "        jump_size=0.6,\n",
    "        max_velocity=0.9,\n",
    "        max_position=3.87,\n",
    "    )\n",
    "num_informants = 4\n",
    "particle_initial_position_scale = (0.0001, 0.087)\n",
    "loss_function = mean_squared_error\n",
    "\n",
    "tentatives = 20\n",
    "\n",
    "final_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(tentatives):\n",
    "    pso = ParticleSwarmOptimisation(\n",
    "        X=train_features.T,\n",
    "        Y=train_targets,\n",
    "        swarm_size=swarm_size,\n",
    "        accel_coeff=accel_coeff,\n",
    "        num_informants=num_informants,\n",
    "        loss_function=loss_function,\n",
    "        particle_initial_position_scale=particle_initial_position_scale,\n",
    "        model=mlp\n",
    "    )\n",
    "    (final_position, final_score, losses) = pso.train(epochs=epochs)\n",
    "    accuracy = pso.get_accuracy(test_features.T, test_targets)\n",
    "    print(f\"Run {i+1}: Final particle fitness: {final_score}\")\n",
    "    final_scores.append(final_score)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "\n",
    "# Histogram that shows accuracy in x and pso that gives that accuracy in y\n",
    "plt.hist(accuracies, bins=10, edgecolor='black')\n",
    "plt.xlabel(\"Test Accuracy (%)\")\n",
    "plt.ylabel(\"Number of PSO runs\")\n",
    "plt.title(\"Distribution of Test Accuracies over PSO Runs\")\n",
    "plt.show()\n",
    "\n",
    "# Print mean accuracy\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "print(f\"Mean Test Accuracy over {tentatives} runs: {mean_accuracy:.2f}% Â± {std_accuracy:.2f}%\")\n",
    "\n",
    "# random : 74.16 +- 2 (20t, 28s)\n",
    "# random : 74.15 +- 2.66 (40t, 56s)\n",
    "# nearest : 72.46 +- 2.35 (40t, 58.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bec4cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class PsoGenome:\n",
    "#     swarm_size: int\n",
    "#     accel_coeff: AccelerationCoefficients\n",
    "#     num_informants: int\n",
    "#     particle_initial_position_scale: Tuple[float, float]\n",
    "#     loss_function: callable\n",
    "\n",
    "#     def crossovers(self, other: 'PsoGenome') -> 'PsoGenome':\n",
    "#         # Implement crossover logic\n",
    "#         pass\n",
    "\n",
    "# class GeneticIndividual:\n",
    "#     def __init__(self, genome: np.ndarray):\n",
    "#         self.genome = genome\n",
    "#         self.fitness: float = float('inf')\n",
    "\n",
    "# class GeneticPsoOptimizer:\n",
    "#     def __init__(self, population_size: int, mutation_rate: float, crossover_rate: float, model: Sequential, loss_function):\n",
    "#         self.population_size = population_size\n",
    "#         self.mutation_rate = mutation_rate\n",
    "#         self.crossover_rate = crossover_rate\n",
    "#         self.loss_function = loss_function\n",
    "#         self.population: List[GeneticIndividual] = []\n",
    "#         self.fitnesses: List[float] = [self.evaluate_fitness(individual) for individual in self.population]\n",
    "\n",
    "#     def evaluate_fitness(self, individual: ParticleSwarmOptimisation) -> float:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ba05e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genetic Algorithm for PSO Hyperparameter Optimization generated by ChatGPT\n",
    "# It is designed to find the best genome (hyperparameters of the PSO) because they are hard to fine tune by hand\n",
    "\n",
    "# --- Genome definition -----------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class AccelerationCoefficientsGenome:\n",
    "    inertia_weight: float\n",
    "    cognitive_weight: float\n",
    "    social_weight: float\n",
    "    global_best_weight: float\n",
    "    jump_size: float\n",
    "    max_velocity: float\n",
    "    max_position: float\n",
    "\n",
    "    def mutate(self, mutation_rate: float, ranges: Dict[str, Tuple[float, float]]):\n",
    "        # gaussian perturbation per field with chance\n",
    "        for name in vars(self):\n",
    "            if random.random() < mutation_rate:\n",
    "                lo, hi = ranges[name]\n",
    "                cur = getattr(self, name)\n",
    "                # relative gaussian step\n",
    "                step = (hi - lo) * 0.1\n",
    "                new = cur + random.gauss(0, step)\n",
    "                setattr(self, name, float(np.clip(new, lo, hi)))\n",
    "\n",
    "    @staticmethod\n",
    "    def crossover(a: 'AccelerationCoefficientsGenome', b: 'AccelerationCoefficientsGenome') -> 'AccelerationCoefficientsGenome':\n",
    "        # uniform crossover\n",
    "        out = {}\n",
    "        for name in vars(a):\n",
    "            out[name] = getattr(a, name) if random.random() < 0.5 else getattr(b, name)\n",
    "        return AccelerationCoefficientsGenome(**out)\n",
    "\n",
    "@dataclass\n",
    "class PsoGenome:\n",
    "    swarm_size: int\n",
    "    accel: AccelerationCoefficientsGenome\n",
    "    num_informants: int\n",
    "    particle_initial_position_scale: Tuple[float, float]\n",
    "    # optionally include model architecture: list of hidden layer sizes and activation names\n",
    "    ann_layers: Optional[Tuple[int, ...]] = None\n",
    "    ann_activation: str = \"tanh\"\n",
    "    # keep a pointer/identifier to the loss function if desired (not serializable)\n",
    "    # loss_function: Callable = field(default=None, repr=False)\n",
    "\n",
    "    def copy(self) -> 'PsoGenome':\n",
    "        return copy.deepcopy(self)\n",
    "\n",
    "    def mutate(self, mutation_rate: float, bounds: dict):\n",
    "        # mutate swarm size (discrete), num_informants (discrete), scales and accel\n",
    "        if random.random() < mutation_rate:\n",
    "            self.swarm_size = int(np.clip(self.swarm_size + random.randint(-4, 4), bounds['swarm_size'][0], bounds['swarm_size'][1]))\n",
    "        if random.random() < mutation_rate:\n",
    "            self.num_informants = int(np.clip(self.num_informants + random.randint(-2, 2), 1, max(1, self.swarm_size - 1)))\n",
    "        if random.random() < mutation_rate:\n",
    "            s0, s1 = self.particle_initial_position_scale\n",
    "            s0 += random.gauss(0, (bounds['position_scale'][1] - bounds['position_scale'][0]) * 0.05)\n",
    "            s1 += random.gauss(0, (bounds['bias_scale'][1] - bounds['bias_scale'][0]) * 0.05)\n",
    "            self.particle_initial_position_scale = (float(np.clip(s0, bounds['position_scale'][0], bounds['position_scale'][1])),\n",
    "                                                   float(np.clip(s1, bounds['bias_scale'][0], bounds['bias_scale'][1])))\n",
    "        # mutate acceleration coeffs\n",
    "        self.accel.mutate(mutation_rate, bounds['accel_ranges'])\n",
    "        # mutate architecture (small chance)\n",
    "        if self.ann_layers is not None and random.random() < mutation_rate:\n",
    "            layers = list(self.ann_layers)\n",
    "            if random.random() < 0.5 and len(layers) > 0:\n",
    "                # tweak a layer size\n",
    "                idx = random.randrange(len(layers))\n",
    "                layers[idx] = int(np.clip(layers[idx] + random.randint(-8, 8), 1, 1024))\n",
    "            else:\n",
    "                # either add or remove layer\n",
    "                if random.random() < 0.5 and len(layers) > 1:\n",
    "                    layers.pop(random.randrange(len(layers)))\n",
    "                else:\n",
    "                    # add a small layer\n",
    "                    insert_at = random.randrange(len(layers)+1)\n",
    "                    layers.insert(insert_at, random.randint(1, 32))\n",
    "            self.ann_layers = tuple(layers)\n",
    "\n",
    "    @staticmethod\n",
    "    def crossover(a: 'PsoGenome', b: 'PsoGenome', crossover_rate: float = 0.5) -> 'PsoGenome':\n",
    "        # single-point for architecture, uniform for many numeric\n",
    "        child = a.copy()\n",
    "        # swarm size: average with some chance\n",
    "        child.swarm_size = int((a.swarm_size if random.random() < 0.5 else b.swarm_size))\n",
    "        child.num_informants = int((a.num_informants if random.random() < 0.5 else b.num_informants))\n",
    "        child.particle_initial_position_scale = (a.particle_initial_position_scale if random.random() < 0.5 else b.particle_initial_position_scale)\n",
    "        child.accel = AccelerationCoefficientsGenome.crossover(a.accel, b.accel)\n",
    "        # architecture crossover (if both defined)\n",
    "        if a.ann_layers and b.ann_layers:\n",
    "            if random.random() < crossover_rate:\n",
    "                # one-point crossover on layer lists\n",
    "                la, lb = list(a.ann_layers), list(b.ann_layers)\n",
    "                cut_a = random.randrange(len(la))\n",
    "                cut_b = random.randrange(len(lb))\n",
    "                new_layers = tuple(la[:cut_a] + lb[cut_b:])\n",
    "                child.ann_layers = new_layers\n",
    "        else:\n",
    "            child.ann_layers = a.ann_layers or b.ann_layers\n",
    "        return child\n",
    "\n",
    "# --- Evaluator -------------------------------------------------------------\n",
    "\n",
    "class PsoEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        Y: np.ndarray,\n",
    "        X_test: np.ndarray,\n",
    "        Y_test: np.ndarray,\n",
    "        base_model_builder: Callable[[PsoGenome], Any],\n",
    "        loss_function: Callable[[np.ndarray, np.ndarray], float],\n",
    "        max_train_seconds: float = 10.0,\n",
    "        patience_window: int = 20,\n",
    "        num_genome_repeats_per_iteration: int = 3,\n",
    "        max_repeats_per_genome: int = 30,\n",
    "        explosion_factor: float = 1e6,\n",
    "        accuracy_checks_every: int = 10,\n",
    "        verbose: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        base_model_builder: function(genome)->model where model implements the interface expected by ParticleSwarmOptimisation:\n",
    "            - randomize(weight_scale, bias_scale)\n",
    "            - to_vector()/from_vector()\n",
    "            - forward(X)\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        self.base_model_builder = base_model_builder\n",
    "        self.loss_function = loss_function\n",
    "        self.max_train_seconds = max_train_seconds\n",
    "        self.patience_window = patience_window\n",
    "        self.num_genome_repeats_per_iteration = num_genome_repeats_per_iteration\n",
    "        self.max_repeats_per_genome = max_repeats_per_genome\n",
    "        self.explosion_factor = explosion_factor\n",
    "        self.accuracy_checks_every = accuracy_checks_every\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.cache: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    def evaluate(self, genome: PsoGenome) -> float:\n",
    "        \"\"\"\n",
    "        Returns scalar fitness. Lower is better.\n",
    "        Implements:\n",
    "         - time-limited training\n",
    "         - early stopping on recent-window no-improvement (penalise)\n",
    "         - explosion detection (penalise)\n",
    "        \"\"\"\n",
    "        key = str(genome)\n",
    "        if key in self.cache and self.cache[key]['repeats'] >= self.max_repeats_per_genome:\n",
    "            return self.cache[key]['acc']\n",
    "\n",
    "        # build model\n",
    "        model = self.base_model_builder(genome)\n",
    "\n",
    "        # build PSO with the genome's params\n",
    "        accel = genome.accel\n",
    "        accel_obj = AccelerationCoefficients(\n",
    "            inertia_weight=accel.inertia_weight,\n",
    "            cognitive_weight=accel.cognitive_weight,\n",
    "            social_weight=accel.social_weight,\n",
    "            global_best_weight=accel.global_best_weight,\n",
    "            jump_size=accel.jump_size,\n",
    "            max_velocity=accel.max_velocity,\n",
    "            max_position=accel.max_position\n",
    "        )\n",
    "        \n",
    "        accuracies = []\n",
    "        \n",
    "        for _ in range(self.num_genome_repeats_per_iteration):\n",
    "            pso = ParticleSwarmOptimisation(\n",
    "                X=self.X, Y=self.Y,\n",
    "                swarm_size=genome.swarm_size,\n",
    "                accel_coeff=accel_obj,\n",
    "                num_informants=max(1, min(genome.num_informants, genome.swarm_size - 1)),\n",
    "                loss_function=self.loss_function,\n",
    "                particle_initial_position_scale=genome.particle_initial_position_scale,\n",
    "                model=model\n",
    "            )\n",
    "\n",
    "            start_time = time.time()\n",
    "            last_losses = []\n",
    "            try:\n",
    "                epoch = 0\n",
    "                # replace PSO.train loop with a time-aware training\n",
    "                pso.update_informants()\n",
    "                # compute an initial loss to detect explosion (if available)\n",
    "                # We'll compute first fitness properly\n",
    "                initial_fitness = pso.update_best_global()\n",
    "                while True:\n",
    "                    # check time limit\n",
    "                    if time.time() - start_time > self.max_train_seconds:\n",
    "                        break\n",
    "                    # iterate a small PSO step: velocities, positions, recompute bests\n",
    "                    pso.update_velocities()\n",
    "                    pso.update_positions()\n",
    "                    avg_fitness = pso.update_best_global()\n",
    "                    last_losses.append(pso.best_global_fitness)\n",
    "\n",
    "                    # explosion detection\n",
    "                    if avg_fitness > initial_fitness * self.explosion_factor:\n",
    "                        # heavy penalty\n",
    "                        if self.verbose:\n",
    "                            print(\"[eval] explosion detected. stopping early.\")\n",
    "                        accuracies.append(0.0)\n",
    "                        break\n",
    "\n",
    "                    if epoch % self.accuracy_checks_every == 0:\n",
    "                        acc = pso.get_accuracy(self.X_test, self.Y_test)\n",
    "                        accuracies.append(acc)\n",
    "                    # early stopping: check last window\n",
    "                    if len(last_losses) > self.patience_window:\n",
    "                        # consider improvement if best decreased at least once in window\n",
    "                        window = last_losses[-self.patience_window:]\n",
    "                        if max(window) < window[0]:  # no improvement\n",
    "                            if self.verbose:\n",
    "                                print(f\"[eval] early stopping at epoch {epoch}\")\n",
    "                            accuracies.append(pso.get_accuracy(self.X_test, self.Y_test))\n",
    "                            break\n",
    "                    epoch += 1\n",
    "                # normal return: the best found\n",
    "                acc = pso.get_accuracy(self.X_test, self.Y_test)\n",
    "                if self.verbose:\n",
    "                    print(f\"[eval] completed training epochs: {epoch}, accuracy: {acc:.6g}\")\n",
    "                accuracies.append(acc)\n",
    "            except Exception as e:\n",
    "                # crash in training -> penalize heavily\n",
    "                if self.verbose:\n",
    "                    print(\"[eval] Exception during PSO eval:\", e)\n",
    "                accuracies.append(0.0)\n",
    "            \n",
    "        if key in self.cache:\n",
    "            self.cache[key]['repeats'] += self.num_genome_repeats_per_iteration\n",
    "        else:\n",
    "            self.cache[key] = {'repeats': self.num_genome_repeats_per_iteration, 'accuracies': []}\n",
    "        updated_accuracies = self.cache[key]['accuracies'] + accuracies\n",
    "        mean_accuracy = np.mean(updated_accuracies)\n",
    "        self.cache[key]['acc'] = mean_accuracy\n",
    "\n",
    "        return mean_accuracy\n",
    "\n",
    "# --- Genetic algorithm ----------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class GeneticIndividual:\n",
    "    genome: PsoGenome\n",
    "    accuracy: float = float('inf')\n",
    "\n",
    "class GeneticPsoOptimizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        evaluator: PsoEvaluator,\n",
    "        population_size: int = 20,\n",
    "        generations: int = 30,\n",
    "        mutation_rate: float = 0.1,\n",
    "        crossover_rate: float = 0.8,\n",
    "        elitism: int = 2,\n",
    "        tournament_k: int = 3,\n",
    "        parallel: bool = True,\n",
    "    ):\n",
    "        self.evaluator = evaluator\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.elitism = elitism\n",
    "        self.tournament_k = tournament_k\n",
    "        self.parallel = parallel\n",
    "        self.population: List[GeneticIndividual] = []\n",
    "\n",
    "    def initialize(self, seed_genome_factory: Callable[[], PsoGenome]):\n",
    "        self.population = [GeneticIndividual(seed_genome_factory()) for _ in range(self.population_size)]\n",
    "\n",
    "    def evaluate_population(self):\n",
    "        # Evaluate all individuals (optionally in parallel)\n",
    "        if self.parallel:\n",
    "            with mp.Pool(max(1, mp.cpu_count() - 1)) as pool:\n",
    "                genomes = [ind.genome for ind in self.population]\n",
    "                results = pool.map(self.evaluator.evaluate, genomes)\n",
    "            for ind, f in zip(self.population, results):\n",
    "                ind.accuracy = f\n",
    "        else:\n",
    "            for ind in self.population:\n",
    "                ind.accuracy = self.evaluator.evaluate(ind.genome)\n",
    "\n",
    "    def tournament_select(self) -> PsoGenome:\n",
    "        contenders = random.sample(self.population, self.tournament_k)\n",
    "        best = max(contenders, key=lambda ind: ind.accuracy)\n",
    "        return best.genome.copy()\n",
    "\n",
    "    def step(self):\n",
    "        # create next generation\n",
    "        new_pop: List[GeneticIndividual] = []\n",
    "        # elitism: carry best individuals\n",
    "        sorted_pop = sorted(self.population, key=lambda ind: ind.accuracy, reverse=True)\n",
    "        for i in range(self.elitism):\n",
    "            new_pop.append(GeneticIndividual(sorted_pop[i].genome.copy(), sorted_pop[i].accuracy))\n",
    "        # fill rest\n",
    "        while len(new_pop) < self.population_size:\n",
    "            parent_a = self.tournament_select()\n",
    "            if random.random() < self.crossover_rate:\n",
    "                parent_b = self.tournament_select()\n",
    "                child_genome = PsoGenome.crossover(parent_a, parent_b, crossover_rate=self.crossover_rate)\n",
    "            else:\n",
    "                child_genome = parent_a.copy()\n",
    "            child_genome.mutate(self.mutation_rate, bounds=self._bounds())\n",
    "            new_pop.append(GeneticIndividual(child_genome))\n",
    "        self.population = new_pop\n",
    "\n",
    "    def run(self, seed_genome_factory: Callable[[], PsoGenome], verbose: bool = True):\n",
    "        self.initialize(seed_genome_factory)\n",
    "        self.evaluate_population()\n",
    "        best_history = []\n",
    "        for g in range(self.generations):\n",
    "            if verbose:\n",
    "                best = max(self.population, key=lambda ind: ind.accuracy)\n",
    "                avg_fitness = sum(ind.accuracy for ind in self.population) / len(self.population)\n",
    "                print(f\"[GA] gen {g:02d} best {best.accuracy:.6g} avg {avg_fitness:.6g}\")\n",
    "                with open(\"ga_pso_log.csv\", \"a\") as f:\n",
    "                    f.write(f\"{g},{best.accuracy},{avg_fitness}\\n\")\n",
    "            self.step()\n",
    "            self.evaluate_population()\n",
    "            best_history.append(min(self.population, key=lambda ind: ind.accuracy).accuracy)\n",
    "        # final best\n",
    "        best_ind = min(self.population, key=lambda ind: ind.accuracy)\n",
    "        return best_ind, best_history\n",
    "\n",
    "    def _bounds(self):\n",
    "        # central place for bounds used by mutate: feel free to expose\n",
    "        return {\n",
    "            'swarm_size': (4, 200),\n",
    "            'position_scale': (1e-4, 1.0),\n",
    "            'bias_scale': (1e-6, 1.0),\n",
    "            'accel_ranges': {\n",
    "                'inertia_weight': (0.0, 2.0),\n",
    "                'cognitive_weight': (0.0, 4.0),\n",
    "                'social_weight': (0.0, 4.0),\n",
    "                'global_best_weight': (0.0, 4.0),\n",
    "                'jump_size': (1e-4, 2.0),\n",
    "                'max_velocity': (1e-6, 10.0),\n",
    "                'max_position': (1e-3, 100.0),\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca917c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[GA] gen 00 best 0 avg 0\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[GA] gen 01 best 0 avg 0\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[GA] gen 02 best 0 avg 0\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[GA] gen 03 best 0 avg 0\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[GA] gen 04 best 0 avg 0\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n",
      "[eval] Exception during PSO eval: 'ParticleSwarmOptimisation' object has no attribute 'update_informants'\n"
     ]
    }
   ],
   "source": [
    "# Example usage of GeneticPsoOptimizer\n",
    "\n",
    "optimizer = GeneticPsoOptimizer(\n",
    "    evaluator=PsoEvaluator(\n",
    "        X=train_features.T,\n",
    "        Y=train_targets,\n",
    "        X_test=test_features.T,\n",
    "        Y_test=test_targets,\n",
    "        base_model_builder=lambda genome: Sequential(\n",
    "            *(\n",
    "                [Linear(size_input=train_features.shape[1], size_hidden=genome.ann_layers[0])] +\n",
    "                sum(\n",
    "                    ([ActivationReLU(), Linear(size_input=genome.ann_layers[i], size_hidden=genome.ann_layers[i+1])]\n",
    "                     for i in range(len(genome.ann_layers)-1)),\n",
    "                    []\n",
    "                ) +\n",
    "                [ActivationReLU(), Linear(size_input=genome.ann_layers[-1], size_hidden=1)]\n",
    "            ) if genome.ann_layers else\n",
    "            [\n",
    "                Linear(size_input=train_features.shape[1], size_hidden=32),\n",
    "                ActivationReLU(),\n",
    "                Linear(size_input=32, size_hidden=16),\n",
    "                ActivationReLU(),\n",
    "                Linear(size_input=16, size_hidden=1)\n",
    "            ]\n",
    "        ),\n",
    "        loss_function=mean_squared_error,\n",
    "        max_train_seconds=0.3,\n",
    "        patience_window=20,\n",
    "        num_genome_repeats_per_iteration=2,\n",
    "        max_repeats_per_genome=10,\n",
    "        explosion_factor=1e2,\n",
    "        accuracy_checks_every=10,\n",
    "        verbose=True\n",
    "    ),\n",
    "    population_size=8,\n",
    "    generations=5,\n",
    "    mutation_rate=0.2,\n",
    "    crossover_rate=0.7,\n",
    "    elitism=6,\n",
    "    tournament_k=3,\n",
    "    parallel=False\n",
    ")\n",
    "\n",
    "optimizer.run(\n",
    "    seed_genome_factory=lambda: PsoGenome(\n",
    "        swarm_size=random.randint(10, 200),\n",
    "        accel=AccelerationCoefficientsGenome(\n",
    "            inertia_weight=random.uniform(0.2, 0.9),\n",
    "            cognitive_weight=random.uniform(0.5, 3.0),\n",
    "            social_weight=random.uniform(0.2, 2.0),\n",
    "            global_best_weight=random.uniform(0.1, 2.0),\n",
    "            jump_size=random.uniform(0.01, 1.0),\n",
    "            max_velocity=random.uniform(0.001, 2.0),\n",
    "            max_position=random.uniform(0.1, 10.0)\n",
    "        ),\n",
    "        num_informants=random.randint(1, 10),\n",
    "        particle_initial_position_scale=(random.uniform(0.0001, 0.1), random.uniform(0.0001, 0.1)),\n",
    "        ann_layers=(32, 16),\n",
    "        ann_activation=\"relu\"\n",
    "    ),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Save output to a file\n",
    "with open(\"genetic_pso_optimizer_result.txt\", \"w\") as f:\n",
    "    best_individual = max(optimizer.population, key=lambda ind: ind.accuracy)\n",
    "    f.write(f\"Best accuracy: {best_individual.accuracy}\\n\")\n",
    "    f.write(f\"Best genome: {best_individual.genome}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e90e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
