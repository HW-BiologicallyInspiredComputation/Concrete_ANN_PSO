# Genetic Algorithm for PSO Hyperparameter Optimization generated by ChatGPT
# It is designed to find the best genome (hyperparameters of the PSO) because they are hard to fine tune by hand

from __future__ import annotations
import time
import copy
import random
import math
from dataclasses import dataclass, field
from typing import Tuple, List, Optional, Callable, Any, Dict
import numpy as np
import multiprocessing as mp
from utils import mean_squared_error
from pso import ParticleSwarmOptimisation, AccelerationCoefficients
from sequential import Sequential
from linear import Linear
from activations import ActivationReLU

from data import load_data

# --- Genome definition -----------------------------------------------------

@dataclass
class AccelerationCoefficientsGenome:
    inertia_weight: float
    cognitive_weight: float
    social_weight: float
    global_best_weight: float
    jump_size: float
    max_velocity: float
    max_position: float

    def mutate(self, mutation_rate: float, ranges: Dict[str, Tuple[float, float]]):
        # gaussian perturbation per field with chance
        for name in vars(self):
            if random.random() < mutation_rate:
                lo, hi = ranges[name]
                cur = getattr(self, name)
                # relative gaussian step
                step = (hi - lo) * 0.1
                new = cur + random.gauss(0, step)
                setattr(self, name, float(np.clip(new, lo, hi)))

    @staticmethod
    def crossover(a: 'AccelerationCoefficientsGenome', b: 'AccelerationCoefficientsGenome') -> 'AccelerationCoefficientsGenome':
        # uniform crossover
        out = {}
        for name in vars(a):
            out[name] = getattr(a, name) if random.random() < 0.5 else getattr(b, name)
        return AccelerationCoefficientsGenome(**out)

@dataclass
class PsoGenome:
    swarm_size: int
    accel: AccelerationCoefficientsGenome
    num_informants: int
    particle_initial_position_scale: Tuple[float, float]
    # optionally include model architecture: list of hidden layer sizes and activation names
    ann_layers: Optional[Tuple[int, ...]] = None
    ann_activation: str = "tanh"
    # keep a pointer/identifier to the loss function if desired (not serializable)
    # loss_function: Callable = field(default=None, repr=False)

    def copy(self) -> 'PsoGenome':
        return copy.deepcopy(self)

    def mutate(self, mutation_rate: float, bounds: dict):
        # mutate swarm size (discrete), num_informants (discrete), scales and accel
        if random.random() < mutation_rate:
            self.swarm_size = int(np.clip(self.swarm_size + random.randint(-4, 4), bounds['swarm_size'][0], bounds['swarm_size'][1]))
        if random.random() < mutation_rate:
            self.num_informants = int(np.clip(self.num_informants + random.randint(-2, 2), 1, max(1, self.swarm_size - 1)))
        if random.random() < mutation_rate:
            s0, s1 = self.particle_initial_position_scale
            s0 += random.gauss(0, (bounds['position_scale'][1] - bounds['position_scale'][0]) * 0.05)
            s1 += random.gauss(0, (bounds['bias_scale'][1] - bounds['bias_scale'][0]) * 0.05)
            self.particle_initial_position_scale = (float(np.clip(s0, bounds['position_scale'][0], bounds['position_scale'][1])),
                                                   float(np.clip(s1, bounds['bias_scale'][0], bounds['bias_scale'][1])))
        # mutate acceleration coeffs
        self.accel.mutate(mutation_rate, bounds['accel_ranges'])
        # mutate architecture (small chance)
        if self.ann_layers is not None and random.random() < mutation_rate:
            layers = list(self.ann_layers)
            if random.random() < 0.5 and len(layers) > 0:
                # tweak a layer size
                idx = random.randrange(len(layers))
                layers[idx] = int(np.clip(layers[idx] + random.randint(-8, 8), 1, 1024))
            else:
                # either add or remove layer
                if random.random() < 0.5 and len(layers) > 1:
                    layers.pop(random.randrange(len(layers)))
                else:
                    # add a small layer
                    insert_at = random.randrange(len(layers)+1)
                    layers.insert(insert_at, random.randint(1, 32))
            self.ann_layers = tuple(layers)

    @staticmethod
    def crossover(a: 'PsoGenome', b: 'PsoGenome', crossover_rate: float = 0.5) -> 'PsoGenome':
        # single-point for architecture, uniform for many numeric
        child = a.copy()
        # swarm size: average with some chance
        child.swarm_size = int((a.swarm_size if random.random() < 0.5 else b.swarm_size))
        child.num_informants = int((a.num_informants if random.random() < 0.5 else b.num_informants))
        child.particle_initial_position_scale = (a.particle_initial_position_scale if random.random() < 0.5 else b.particle_initial_position_scale)
        child.accel = AccelerationCoefficientsGenome.crossover(a.accel, b.accel)
        # architecture crossover (if both defined)
        if a.ann_layers and b.ann_layers:
            if random.random() < crossover_rate:
                # one-point crossover on layer lists
                la, lb = list(a.ann_layers), list(b.ann_layers)
                cut_a = random.randrange(len(la))
                cut_b = random.randrange(len(lb))
                new_layers = tuple(la[:cut_a] + lb[cut_b:])
                child.ann_layers = new_layers
        else:
            child.ann_layers = a.ann_layers or b.ann_layers
        return child

# --- Evaluator -------------------------------------------------------------

class PsoEvaluator:
    def __init__(
        self,
        X: np.ndarray,
        Y: np.ndarray,
        base_model_builder: Callable[[PsoGenome], Any],
        loss_function: Callable[[np.ndarray, np.ndarray], float],
        max_train_seconds: float = 10.0,
        patience_window: int = 20,
        explosion_factor: float = 1e6,
        verbose: bool = False
    ):
        """
        base_model_builder: function(genome)->model where model implements the interface expected by ParticleSwarmOptimisation:
            - randomize(weight_scale, bias_scale)
            - to_vector()/from_vector()
            - forward(X)
        """
        self.X = X
        self.Y = Y
        self.base_model_builder = base_model_builder
        self.loss_function = loss_function
        self.max_train_seconds = max_train_seconds
        self.patience_window = patience_window
        self.explosion_factor = explosion_factor
        self.verbose = verbose

    def evaluate(self, genome: PsoGenome) -> float:
        """
        Returns scalar fitness. Lower is better.
        Implements:
         - time-limited training
         - early stopping on recent-window no-improvement (penalise)
         - explosion detection (penalise)
        """
        # build model
        model = self.base_model_builder(genome)

        # build PSO with the genome's params
        accel = genome.accel
        accel_obj = AccelerationCoefficients(
            inertia_weight=accel.inertia_weight,
            cognitive_weight=accel.cognitive_weight,
            social_weight=accel.social_weight,
            global_best_weight=accel.global_best_weight,
            jump_size=accel.jump_size,
            max_velocity=accel.max_velocity,
            max_position=accel.max_position
        )

        pso = ParticleSwarmOptimisation(
            X=self.X, Y=self.Y,
            swarm_size=genome.swarm_size,
            epochs=1000000,  # huge number -- we will stop by time
            accel_coeff=accel_obj,
            num_informants=max(1, min(genome.num_informants, genome.swarm_size - 1)),
            loss_function=self.loss_function,
            particle_initial_position_scale=genome.particle_initial_position_scale,
            model=model
        )

        start_time = time.time()
        last_losses = []
        best_history = []
        try:
            # replace PSO.train loop with a time-aware training
            pso.update_informants()
            epoch = 0
            best_global_fitness = pso.best_global_fitness
            # compute an initial loss to detect explosion (if available)
            # We'll compute first fitness properly
            avg = pso.update_best_global(0)
            initial_loss = max(1e-12, pso.best_global_fitness or avg or 1.0)
            # if self.verbose:
            #     print(f"[eval] initial loss {initial_loss:.6g}")
            while True:
                # check time limit
                if time.time() - start_time > self.max_train_seconds:
                    break
                # iterate a small PSO step: velocities, positions, recompute bests
                pso.update_velocities()
                pso.update_positions()
                avg_fitness = pso.update_best_global(epoch)
                best_history.append(pso.best_global_fitness)
                last_losses.append(pso.best_global_fitness)
                # explosion detection
                if pso.best_global_fitness > initial_loss * self.explosion_factor:
                    # heavy penalty
                    if self.verbose:
                        print("[eval] explosion detected. stopping early.")
                    return float('inf')
                # early stopping: check last window
                if len(last_losses) > self.patience_window:
                    # consider improvement if best decreased at least once in window
                    window = last_losses[-self.patience_window:]
                    if min(window) >= window[0]:  # no improvement
                        # penalize slightly, but still return current best
                        penalty = 1.0 + 0.1 * math.log(1 + epoch)
                        if self.verbose:
                            print(f"[eval] early stopping at epoch {epoch} with penalty {penalty:.6g}")
                        return pso.best_global_fitness * penalty
                epoch += 1
            # normal return: the best found
            if self.verbose:
                print(f"[eval] completed training epochs: {epoch}, best fitness: {pso.best_global_fitness:.6g}")
            return pso.best_global_fitness
        except Exception as e:
            # crash in training -> penalize heavily
            if self.verbose:
                print("[eval] Exception during PSO eval:", e)
            return float('inf')

# --- Genetic algorithm ----------------------------------------------------

@dataclass
class GeneticIndividual:
    genome: PsoGenome
    fitness: float = float('inf')

class GeneticPsoOptimizer:
    def __init__(
        self,
        evaluator: PsoEvaluator,
        population_size: int = 20,
        generations: int = 30,
        mutation_rate: float = 0.1,
        crossover_rate: float = 0.8,
        elitism: int = 2,
        tournament_k: int = 3,
        parallel: bool = True,
    ):
        self.evaluator = evaluator
        self.population_size = population_size
        self.generations = generations
        self.mutation_rate = mutation_rate
        self.crossover_rate = crossover_rate
        self.elitism = elitism
        self.tournament_k = tournament_k
        self.parallel = parallel
        self.population: List[GeneticIndividual] = []

    def initialize(self, seed_genome_factory: Callable[[], PsoGenome]):
        self.population = [GeneticIndividual(seed_genome_factory()) for _ in range(self.population_size)]

    def evaluate_population(self):
        # Evaluate all individuals (optionally in parallel)
        if self.parallel:
            with mp.Pool(max(1, mp.cpu_count() - 1)) as pool:
                genomes = [ind.genome for ind in self.population]
                results = pool.map(self.evaluator.evaluate, genomes)
            for ind, f in zip(self.population, results):
                ind.fitness = f
        else:
            for ind in self.population:
                ind.fitness = self.evaluator.evaluate(ind.genome)

    def tournament_select(self) -> PsoGenome:
        contenders = random.sample(self.population, self.tournament_k)
        best = min(contenders, key=lambda ind: ind.fitness)
        return best.genome.copy()

    def step(self):
        # create next generation
        new_pop: List[GeneticIndividual] = []
        # elitism: carry best individuals
        sorted_pop = sorted(self.population, key=lambda ind: ind.fitness)
        for i in range(self.elitism):
            new_pop.append(GeneticIndividual(sorted_pop[i].genome.copy(), sorted_pop[i].fitness))
        # fill rest
        while len(new_pop) < self.population_size:
            parent_a = self.tournament_select()
            if random.random() < self.crossover_rate:
                parent_b = self.tournament_select()
                child_genome = PsoGenome.crossover(parent_a, parent_b, crossover_rate=self.crossover_rate)
            else:
                child_genome = parent_a.copy()
            child_genome.mutate(self.mutation_rate, bounds=self._bounds())
            new_pop.append(GeneticIndividual(child_genome))
        self.population = new_pop

    def run(self, seed_genome_factory: Callable[[], PsoGenome], verbose: bool = True):
        self.initialize(seed_genome_factory)
        self.evaluate_population()
        best_history = []
        for g in range(self.generations):
            if verbose:
                best = min(self.population, key=lambda ind: ind.fitness)
                avg_fitness = sum(ind.fitness for ind in self.population) / len(self.population)
                print(f"[GA] gen {g:02d} best {best.fitness:.6g} avg {avg_fitness:.6g}")
                with open("ga_pso_log.csv", "a") as f:
                    f.write(f"{g},{best.fitness},{avg_fitness}\n")
            self.step()
            self.evaluate_population()
            best_history.append(min(self.population, key=lambda ind: ind.fitness).fitness)
        # final best
        best_ind = min(self.population, key=lambda ind: ind.fitness)
        return best_ind, best_history

    def _bounds(self):
        # central place for bounds used by mutate: feel free to expose
        return {
            'swarm_size': (4, 200),
            'position_scale': (1e-4, 1.0),
            'bias_scale': (1e-6, 1.0),
            'accel_ranges': {
                'inertia_weight': (0.0, 1.2),
                'cognitive_weight': (0.0, 4.0),
                'social_weight': (0.0, 4.0),
                'global_best_weight': (0.0, 4.0),
                'jump_size': (1e-4, 2.0),
                'max_velocity': (1e-6, 10.0),
                'max_position': (1e-3, 100.0),
            }
        }


if __name__ == "__main__":
    (train_features, train_targets), (test_features, test_targets) = load_data()

    # Example usage of GeneticPsoOptimizer
    optimizer = GeneticPsoOptimizer(
        evaluator=PsoEvaluator(
            X=train_features.T,
            Y=train_targets,
            base_model_builder=lambda genome: Sequential(
                *(
                    [Linear(size_input=train_features.shape[1], size_hidden=genome.ann_layers[0])] +
                    sum(
                        ([ActivationReLU(), Linear(size_input=genome.ann_layers[i], size_hidden=genome.ann_layers[i+1])]
                        for i in range(len(genome.ann_layers)-1)),
                        []
                    ) +
                    [ActivationReLU(), Linear(size_input=genome.ann_layers[-1], size_hidden=1)]
                ) if genome.ann_layers else
                [
                    Linear(size_input=train_features.shape[1], size_hidden=32),
                    ActivationReLU(),
                    Linear(size_input=32, size_hidden=16),
                    ActivationReLU(),
                    Linear(size_input=16, size_hidden=1)
                ]
            ),
            loss_function=mean_squared_error,
            max_train_seconds=10.0,
            patience_window=10,
            explosion_factor=1e1,
            verbose=False
        ),
        population_size=20,
        generations=30,
        mutation_rate=0.2,
        crossover_rate=0.7,
        elitism=5,
        tournament_k=3,
        parallel=False
    )

    optimizer.run(
        seed_genome_factory=lambda: PsoGenome(
            swarm_size=random.randint(10, 200),
            accel=AccelerationCoefficientsGenome(
                inertia_weight=random.uniform(0.4, 0.9),
                cognitive_weight=random.uniform(1.0, 3.0),
                social_weight=random.uniform(0.5, 2.0),
                global_best_weight=random.uniform(0.1, 1.0),
                jump_size=random.uniform(0.01, 1.0),
                max_velocity=random.uniform(0.001, 1.0),
                max_position=random.uniform(0.1, 10.0)
            ),
            num_informants=random.randint(1, 10),
            particle_initial_position_scale=(random.uniform(0.0001, 0.1), random.uniform(0.0001, 0.1)),
            ann_layers=(32, 16),
            ann_activation="relu"
        ),
        verbose=True
    )

    # Save output to a file
    with open("genetic_pso_optimizer_result.txt", "w") as f:
        best_individual = min(optimizer.population, key=lambda ind: ind.fitness)
        f.write(f"Best fitness: {best_individual.fitness}\n")
        f.write(f"Best genome: {best_individual.genome}\n")
    import pickle
    with open("genetic_pso_optimizer_result.pkl", "wb") as f:
        pickle.dump(optimizer, f)
